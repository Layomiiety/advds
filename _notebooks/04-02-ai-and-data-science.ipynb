{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI and Data Science\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
    "\n",
    "Cambridge\n",
    "\n",
    "### 2024-11-04"
   ],
   "id": "d73c758d-5b46-49ed-a237-1d5fc3635619"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: In the first lecture, we laid out the underpinning\n",
    "phenomena that give us the landscape of data science. In this lecture we\n",
    "unpick the challenges that landscape presents us with. The material\n",
    "gives you context for why data science is very different from standard\n",
    "software engineering, and how data science problems need to be\n",
    "approached including the many different aspects that need to be\n",
    "considered. We will look at the challenges of deploying data science\n",
    "solutions in practice. We categorize them into three groups."
   ],
   "id": "66b76b77-e572-45f7-a97b-ef95f9415d5c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ],
   "id": "f6c8e113-cb55-493a-b637-3a2269833706"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.cell .markdown}\n",
    "\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->\n",
    "<!--\n",
    "\n",
    "* AI and Data Science\n",
    "  * Machine Learning Definition\n",
    "  * Prediction Example from DSA\n",
    "  * Deep Learning\n",
    "  * LLMs – Probability Conversations\n",
    "* The Challenges of Data Science I\n",
    "  * Complexity in Action\n",
    "  * Selective Attention Bias\n",
    "  * Data Theatre\n",
    "  * The Art of Statistics\n",
    "\n",
    "-->"
   ],
   "id": "d29c5e82-e25d-44b8-abbe-e8f632da4888"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Data science is an emerging discipline. That makes it harder to make\n",
    "clean decisions about what any given individual will need to know to\n",
    "become a data scientist. Those of you who are studying now will be those\n",
    "that define the discipline. As we deploy more data driven decision\n",
    "making in the world, the role will be refined. Until we achieve that\n",
    "refinement, your knowledge needs to be broad based.\n",
    "\n",
    "In this lecture we will first continue our theme of how our limitations\n",
    "as humans mean that our analysis of data can be affected, and I will\n",
    "introduce an analogy that should help you understand *how* data science\n",
    "differs significantly from traditional software engineering.\n",
    "\n",
    "<!-- defines the technical variant-->"
   ],
   "id": "586a7611-6aa6-4f4a-8281-2425aebd6cb9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics to Deep Learning\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/statistics-to-deep-learning.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/statistics-to-deep-learning.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "09629c98-3bca-445a-869f-0421528b93f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-2.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-2.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Machine learning allows us to extract knowledge from data to form a\n",
    "prediction.\n",
    "\n",
    "$$\\text{data} + \\text{model} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}$$\n",
    "\n",
    "A machine learning prediction is made by combining a model with data to\n",
    "form the prediction. The manner in which this is done gives us the\n",
    "machine learning *algorithm*.\n",
    "\n",
    "Machine learning models are *mathematical models* which make weak\n",
    "assumptions about data, e.g. smoothness assumptions. By combining these\n",
    "assumptions with the data, we observe we can interpolate between data\n",
    "points or, occasionally, extrapolate into the future.\n",
    "\n",
    "Machine learning is a technology which strongly overlaps with the\n",
    "methodology of statistics. From a historical/philosophical view point,\n",
    "machine learning differs from statistics in that the focus in the\n",
    "machine learning community has been primarily on accuracy of prediction,\n",
    "whereas the focus in statistics is typically on the interpretability of\n",
    "a model and/or validating a hypothesis through data collection.\n",
    "\n",
    "The rapid increase in the availability of compute and data has led to\n",
    "the increased prominence of machine learning. This prominence is\n",
    "surfacing in two different but overlapping domains: data science and\n",
    "artificial intelligence."
   ],
   "id": "d906de96-73a5-4e79-a211-fe0cdf03da19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Model to Decision\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-end-to-end.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml-end-to-end.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The real challenge, however, is end-to-end decision making. Taking\n",
    "information from the environment and using it to drive decision making\n",
    "to achieve goals."
   ],
   "id": "27743c51-831d-48b8-9f41-5c99f109a145"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Statistical Analysis\n",
    "\n",
    "Despite the shift of emphasis, traditional statistical techniques are\n",
    "more important than ever. One of the few ways we have to validate the\n",
    "analyses we create is to make use of visualizations, randomized testing\n",
    "and other forms of statistical analysis. You will have explored some of\n",
    "these ideas in earlier courses in machine learning. In this unit we\n",
    "provide some review material in a practical sheet to bring some of those\n",
    "ideas together in the context of data science."
   ],
   "id": "244403e9-fcf2-4933-99d8-2097d79cc5f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-is-ml.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "What is machine learning? At its most basic level machine learning is a\n",
    "combination of\n",
    "\n",
    "$$\\text{data} + \\text{model} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}$$\n",
    "\n",
    "where *data* is our observations. They can be actively or passively\n",
    "acquired (meta-data). The *model* contains our assumptions, based on\n",
    "previous experience. That experience can be other data, it can come from\n",
    "transfer learning, or it can merely be our beliefs about the\n",
    "regularities of the universe. In humans our models include our inductive\n",
    "biases. The *prediction* is an action to be taken or a categorization or\n",
    "a quality score. The reason that machine learning has become a mainstay\n",
    "of artificial intelligence is the importance of predictions in\n",
    "artificial intelligence. The data and the model are combined through\n",
    "computation.\n",
    "\n",
    "In practice we normally perform machine learning using two functions. To\n",
    "combine data with a model we typically make use of:\n",
    "\n",
    "**a prediction function** it is used to make the predictions. It\n",
    "includes our beliefs about the regularities of the universe, our\n",
    "assumptions about how the world works, e.g., smoothness, spatial\n",
    "similarities, temporal similarities.\n",
    "\n",
    "**an objective function** it defines the ‘cost’ of misprediction.\n",
    "Typically, it includes knowledge about the world’s generating processes\n",
    "(probabilistic objectives) or the costs we pay for mispredictions\n",
    "(empirical risk minimization).\n",
    "\n",
    "The combination of data and model through the prediction function and\n",
    "the objective function leads to a *learning algorithm*. The class of\n",
    "prediction functions and objective functions we can make use of is\n",
    "restricted by the algorithms they lead to. If the prediction function or\n",
    "the objective function are too complex, then it can be difficult to find\n",
    "an appropriate learning algorithm. Much of the academic field of machine\n",
    "learning is the quest for new learning algorithms that allow us to bring\n",
    "different types of models and data together.\n",
    "\n",
    "A useful reference for state of the art in machine learning is the UK\n",
    "Royal Society Report, [Machine Learning: Power and Promise of Computers\n",
    "that Learn by\n",
    "Example](https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf).\n",
    "\n",
    "You can also check my post blog post on [What is Machine\n",
    "Learning?](http://inverseprobability.com/2017/07/17/what-is-machine-learning)."
   ],
   "id": "55e5e45c-d707-444f-afbc-432878d2a4f3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence and Data Science\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/data-science-vs-ai.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/data-science-vs-ai.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Machine learning technologies have been the driver of two related, but\n",
    "distinct disciplines. The first is *data science*. Data science is an\n",
    "emerging field that arises from the fact that we now collect so much\n",
    "data by happenstance, rather than by *experimental design*. Classical\n",
    "statistics is the science of drawing conclusions from data, and to do so\n",
    "statistical experiments are carefully designed. In the modern era we\n",
    "collect so much data that there’s a desire to draw inferences directly\n",
    "from the data.\n",
    "\n",
    "As well as machine learning, the field of data science draws from\n",
    "statistics, cloud computing, data storage (e.g. streaming data),\n",
    "visualization and data mining.\n",
    "\n",
    "In contrast, artificial intelligence technologies typically focus on\n",
    "emulating some form of human behaviour, such as understanding an image,\n",
    "or some speech, or translating text from one form to another. The recent\n",
    "advances in artificial intelligence have come from machine learning\n",
    "providing the automation. But in contrast to data science, in artificial\n",
    "intelligence the data is normally collected with the specific task in\n",
    "mind. In this sense it has strong relations to classical statistics.\n",
    "\n",
    "Classically artificial intelligence worried more about *logic* and\n",
    "*planning* and focused less on data driven decision making. Modern\n",
    "machine learning owes more to the field of *Cybernetics* (Wiener, 1948)\n",
    "than artificial intelligence. Related fields include *robotics*, *speech\n",
    "recognition*, *language understanding* and *computer vision*.\n",
    "\n",
    "There are strong overlaps between the fields, the wide availability of\n",
    "data by happenstance makes it easier to collect data for designing AI\n",
    "systems. These relations are coming through wide availability of sensing\n",
    "technologies that are interconnected by cellular networks, WiFi and the\n",
    "internet. This phenomenon is sometimes known as the *Internet of\n",
    "Things*, but this feels like a dangerous misnomer. We must never forget\n",
    "that we are interconnecting people, not things.\n",
    "\n",
    "<center>\n",
    "\n",
    "Convention for the Protection of *Individuals* with regard to Automatic\n",
    "Processing of *Personal Data* (1981/1/28)\n",
    "\n",
    "</center>"
   ],
   "id": "c8541734-5b37-4575-a6b3-2510a662dede"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Machine Learning do?\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-does-machine-learning-do.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-does-machine-learning-do.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Any process of automation allows us to scale what we do by codifying a\n",
    "process in some way that makes it efficient and repeatable. Machine\n",
    "learning automates by emulating human (or other actions) found in data.\n",
    "Machine learning codifies in the form of a mathematical function that is\n",
    "learnt by a computer. If we can create these mathematical functions in\n",
    "ways in which they can interconnect, then we can also build systems.\n",
    "\n",
    "Machine learning works through codifying a prediction of interest into a\n",
    "mathematical function. For example, we can try and predict the\n",
    "probability that a customer wants to by a jersey given knowledge of\n",
    "their age, and the latitude where they live. The technique known as\n",
    "logistic regression estimates the odds that someone will by a jumper as\n",
    "a linear weighted sum of the features of interest.\n",
    "\n",
    "$$ \\text{odds} = \\frac{p(\\text{bought})}{p(\\text{not bought})} $$\n",
    "\n",
    "$$ \\log \\text{odds}  = w_0 + w_1 \\text{age} + w_2 \\text{latitude}.$$\n",
    "Here $w_0$, $w_1$ and $w_2$ are the parameters of the model. If $w_1$\n",
    "and $w_2$ are both positive, then the log-odds that someone will buy a\n",
    "jumper increase with increasing latitude and age, so the further north\n",
    "you are and the older you are the more likely you are to buy a jumper.\n",
    "The parameter $w_0$ is an offset parameter and gives the log-odds of\n",
    "buying a jumper at zero age and on the equator. It is likely to be\n",
    "negative[1] indicating that the purchase is odds-against. This is also a\n",
    "classical statistical model, and models like logistic regression are\n",
    "widely used to estimate probabilities from ad-click prediction to\n",
    "disease risk.\n",
    "\n",
    "This is called a generalized linear model, we can also think of it as\n",
    "estimating the *probability* of a purchase as a nonlinear function of\n",
    "the features (age, latitude) and the parameters (the $w$ values). The\n",
    "function is known as the *sigmoid* or [logistic\n",
    "function](https://en.wikipedia.org/wiki/Logistic_regression), thus the\n",
    "name *logistic* regression.\n",
    "\n",
    "[1] The logarithm of a number less than one is negative, for a number\n",
    "greater than one the logarithm is positive. So if odds are greater than\n",
    "evens (odds-on) the log-odds are positive, if the odds are less than\n",
    "evens (odds-against) the log-odds will be negative."
   ],
   "id": "85044ed2-f33f-4567-8201-900f2fefa708"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/sigmoid-function.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/sigmoid-function.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "9b5b7b72-6a5b-4cc4-8f4e-a61bb502e61c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "9cb7c6bd-5509-449b-8847-8ca18a202020"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.logistic('./ml/logistic.svg')"
   ],
   "id": "dc8ae313-db9e-4600-bb05-dd66a4989f07"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//ml/logistic.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The logistic function.</i>\n",
    "\n",
    "The function has this characeristic ‘s’-shape (from where the term\n",
    "sigmoid, as in sigma, comes from). It also takes the input from the\n",
    "entire real line and ‘squashes’ it into an output that is between zero\n",
    "and one. For this reason it is sometimes also called a ‘squashing\n",
    "function’.\n",
    "\n",
    "The sigmoid comes from the inverting the odds ratio, $$\n",
    "\\frac{\\pi}{(1-\\pi)}\n",
    "$$ where $\\pi$ is the probability of a positive outcome and $1-\\pi$ is\n",
    "the probability of a negative outcome\n",
    "\n",
    "$$ p(\\text{bought}) =  \\sigma\\left(w_0 + w_1 \\text{age} + w_2 \\text{latitude}\\right).$$\n",
    "\n",
    "In the case where we have *features* to help us predict, we sometimes\n",
    "denote such features as a vector, $\\mathbf{ x}$, and we then use an\n",
    "inner product between the features and the parameters,\n",
    "$\\mathbf{ w}^\\top \\mathbf{ x}= w_1 x_1 + w_2 x_2 + w_3 x_3 ...$, to\n",
    "represent the argument of the sigmoid.\n",
    "\n",
    "$$ p(\\text{bought}) =  \\sigma\\left(\\mathbf{ w}^\\top \\mathbf{ x}\\right).$$\n",
    "More generally, we aim to predict some aspect of our data, $y$, by\n",
    "relating it through a mathematical function, $f(\\cdot)$, to the\n",
    "parameters, $\\mathbf{ w}$ and the data, $\\mathbf{ x}$.\n",
    "\n",
    "$$ y=  f\\left(\\mathbf{ x}, \\mathbf{ w}\\right).$$ We call $f(\\cdot)$ the\n",
    "*prediction function*.\n",
    "\n",
    "To obtain the fit to data, we use a separate function called the\n",
    "*objective function* that gives us a mathematical representation of the\n",
    "difference between our predictions and the real data.\n",
    "\n",
    "$$E(\\mathbf{ w}, \\mathbf{Y}, \\mathbf{X})$$ A commonly used examples (for\n",
    "example in a regression problem) is least squares,\n",
    "$$E(\\mathbf{ w}, \\mathbf{Y}, \\mathbf{X}) = \\sum_{i=1}^n\\left(y_i - f(\\mathbf{ x}_i, \\mathbf{ w})\\right)^2.$$\n",
    "\n",
    "If a linear prediction function is combined with the least squares\n",
    "objective function, then that gives us a classical *linear regression*,\n",
    "another classical statistical model. Statistics often focusses on linear\n",
    "models because it makes interpretation of the model easier.\n",
    "Interpretation is key in statistics because the aim is normally to\n",
    "validate questions by analysis of data. Machine learning has typically\n",
    "focused more on the prediction function itself and worried less about\n",
    "the interpretation of parameters. In statistics, where interpretation is\n",
    "typically more important than prediction, parameters are normally\n",
    "denoted by $\\boldsymbol{\\beta}$ instead of $\\mathbf{ w}$.\n",
    "\n",
    "A key difference between statistics and machine learning, is that\n",
    "(traditionally) machine learning has focussed on predictive capability\n",
    "and statistics has focussed on interpretability. That means that in a\n",
    "statistics class far more emphasis will be placed on interpretation of\n",
    "the parameters. In machine learning, the parameters, \\$, are just a\n",
    "means to an end. But in statistics, when we denote the parameters by\n",
    "$\\boldsymbol{\\beta}$, we often use the parameters to tell us something\n",
    "about the disease.\n",
    "\n",
    "So we move between\n",
    "$$ p(\\text{bought}) =  \\sigma\\left(w_0 + w_1 \\text{age} + w_2 \\text{latitude}\\right).$$\n",
    "\n",
    "to denote the emphasis is on predictive power to\n",
    "\n",
    "$$ p(\\text{bought}) =  \\sigma\\left(\\beta_0 + \\beta_1 \\text{age} + \\beta_2 \\text{latitude}\\right).$$\n",
    "\n",
    "to denote the emphasis is on interpretation of the parameters.\n",
    "\n",
    "Another effect of the focus on prediction in machine learning is that\n",
    "*non-linear* approaches, which can be harder to interpret, are more\n",
    "widely deployedin machine learning – they tend to improve quality of\n",
    "predictions at the expense of interpretability."
   ],
   "id": "815759c7-a457-477e-afc9-35af79dc0fe0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/logistic-regression.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/logistic-regression.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "A logistic regression is an approach to classification which extends the\n",
    "linear basis function models we’ve already explored. Rather than\n",
    "modeling the output of the function directly the assumption is that we\n",
    "model the *log-odds* with the basis functions.\n",
    "\n",
    "The [odds](http://en.wikipedia.org/wiki/Odds) are defined as the ratio\n",
    "of the probability of a positive outcome, to the probability of a\n",
    "negative outcome. If the probability of a positive outcome is denoted by\n",
    "$\\pi$, then the odds are computed as $\\frac{\\pi}{1-\\pi}$. Odds are\n",
    "widely used by [bookmakers](http://en.wikipedia.org/wiki/Bookmaker) in\n",
    "gambling, although a bookmakers odds won’t normalise: i.e. if you look\n",
    "at the equivalent probabilities, and sum over the probability of all\n",
    "outcomes the bookmakers are considering, then you won’t get one. This is\n",
    "how the bookmaker makes a profit. Because a probability is always\n",
    "between zero and one, the odds are always between $0$ and $\\infty$. If\n",
    "the positive outcome is unlikely the odds are close to zero, if it is\n",
    "very likely then the odds become close to infinite. Taking the logarithm\n",
    "of the odds maps the odds from the positive half space to being across\n",
    "the entire real line. Odds that were between 0 and 1 (where the negative\n",
    "outcome was more likely) are mapped to the range between $-\\infty$ and\n",
    "$0$. Odds that are greater than 1 are mapped to the range between $0$\n",
    "and $\\infty$. Considering the log odds therefore takes a number between\n",
    "0 and 1 (the probability of positive outcome) and maps it to the entire\n",
    "real line. The function that does this is known as the [logit\n",
    "function](http://en.wikipedia.org/wiki/Logit),\n",
    "$g^{-1}(p_i) = \\log\\frac{p_i}{1-p_i}$. This function is known as a *link\n",
    "function*.\n",
    "\n",
    "For a standard regression we take, $$\n",
    "f(\\mathbf{ x}) = \\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}),\n",
    "$$ if we want to perform classification we perform a logistic\n",
    "regression. $$\n",
    "\\log \\frac{\\pi}{(1-\\pi)} = \\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x})\n",
    "$$ where the odds ratio between the positive class and the negative\n",
    "class is given by $$\n",
    "\\frac{\\pi}{(1-\\pi)}\n",
    "$$ The odds can never be negative, but can take any value from 0 to\n",
    "$\\infty$. We have defined the link function as taking the form\n",
    "$g^{-1}(\\cdot)$ implying that the inverse link function is given by\n",
    "$g(\\cdot)$. Since we have defined, $$\n",
    "g^{-1}(\\pi) =\n",
    "\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x})\n",
    "$$ we can write $\\pi$ in terms of the *inverse link* function,\n",
    "$g(\\cdot)$ as $$\n",
    "\\pi = g(\\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x})).\n",
    "$$"
   ],
   "id": "1f64a0a2-df43-4522-b8d2-e068e6df0b12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "fd46ceb9-f9b7-4a76-a616-3b31c85b6e94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.logistic('./ml/logistic.svg')"
   ],
   "id": "2fcea727-5bb1-4211-8561-ad7eeb412f91"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Function\n",
    "\n",
    "We’ll define our prediction, objective and gradient functions below. But\n",
    "before we start, we need to define a basis function for our model. Let’s\n",
    "start with the linear basis."
   ],
   "id": "f738703e-b37f-4341-9748-5389136ceb55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "68fae70b-aa1e-4a3f-8504-fbfdc41e824c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ],
   "id": "b6a1b9de-d91b-4074-9621-5fab85cf1af7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.linear"
   ],
   "id": "bfa09248-f5f2-4b84-a8c6-690d24ce281e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function\n",
    "\n",
    "Now we have the basis function let’s define the prediction function."
   ],
   "id": "86aa94b4-c261-4ef1-a9c4-51f464739526"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "fc7a8737-dc00-47ac-b5b9-4bc2a96f32ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x, basis=linear, **kwargs):\n",
    "    \"Generates the prediction function and the basis matrix.\"\n",
    "    Phi = basis(x, **kwargs)\n",
    "    f = np.dot(Phi, w)\n",
    "    return 1./(1+np.exp(-f)), Phi"
   ],
   "id": "a4344403-2e33-4016-b1f3-6c2de3343c26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inverse of the link function is known as the\n",
    "[logistic](http://en.wikipedia.org/wiki/Logistic_function) (thus the\n",
    "name logistic regression) or sometimes it is called the sigmoid\n",
    "function. For a particular value of the input to the link function,\n",
    "$f_i = \\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}_i)$ we can plot\n",
    "the value of the inverse link function as below.\n",
    "\n",
    "By replacing the inverse link with the sigmoid we can write $\\pi$ as a\n",
    "function of the input and the parameter vector as, $$\n",
    "\\pi(\\mathbf{ x},\\mathbf{ w}) = \\frac{1}{1+\\exp\\left(-\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x})\\right)}.\n",
    "$$ The process for logistic regression is as follows. Compute the output\n",
    "of a standard linear basis function composition\n",
    "($\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x})$, as we did for\n",
    "linear regression) and then apply the inverse link function,\n",
    "$g(\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}))$. In logistic\n",
    "regression this involves *squashing* it with the logistic (or sigmoid)\n",
    "function. Use this value, which now has an interpretation as a\n",
    "*probability* in a Bernoulli distribution to form the likelihood. Then\n",
    "we can assume conditional independence of each data point given the\n",
    "parameters and develop a likelihod for the entire data set.\n",
    "\n",
    "As we discussed last time, the Bernoulli likelihood is of the form, $$\n",
    "P(y_i|\\mathbf{ w}, \\mathbf{ x}) =\n",
    "\\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\n",
    "$$ which we can think of as clever trick for mathematically switching\n",
    "between two probabilities if we were to write it as code it would be\n",
    "better described as\n",
    "\n",
    "``` python\n",
    "def bernoulli(x, y, pi):\n",
    "    if y == 1:\n",
    "        return pi(x)\n",
    "    else:\n",
    "        return 1-pi(x)\n",
    "```\n",
    "\n",
    "but writing it mathematically makes it easier to write our objective\n",
    "function within a single mathematical equation."
   ],
   "id": "1274ab1c-2165-4ab4-bd4e-526c9f7649dc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood\n",
    "\n",
    "To obtain the parameters of the model, we need to maximize the\n",
    "likelihood, or minimize the objective function, normally taken to be the\n",
    "negative log likelihood. With a data conditional independence assumption\n",
    "the likelihood has the form, $$\n",
    "P(\\mathbf{ y}|\\mathbf{ w},\n",
    "\\mathbf{X}) = \\prod_{i=1}^nP(y_i|\\mathbf{ w}, \\mathbf{ x}_i). \n",
    "$$ which can be written as a log likelihood in the form $$\n",
    "\\log P(\\mathbf{ y}|\\mathbf{ w},\n",
    "\\mathbf{X}) = \\sum_{i=1}^n\\log P(y_i|\\mathbf{ w}, \\mathbf{ x}_i) = \\sum_{i=1}^n\n",
    "y_i \\log \\pi_i + \\sum_{i=1}^n(1-y_i)\\log (1-\\pi_i)\n",
    "$$ and if we take the probability of positive outcome for the $i$th data\n",
    "point to be given by $$\n",
    "\\pi_i = g\\left(\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}_i)\\right),\n",
    "$$ where $g(\\cdot)$ is the *inverse* link function, then this leads to\n",
    "an objective function of the form, $$\n",
    "E(\\mathbf{ w}) = -  \\sum_{i=1}^ny_i \\log\n",
    "g\\left(\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}_i)\\right) -\n",
    "\\sum_{i=1}^n(1-y_i)\\log \\left(1-g\\left(\\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}_i)\\right)\\right).\n",
    "$$"
   ],
   "id": "23760b11-035a-4aaf-83a8-1779a4eda620"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "00815b07-c481-4849-8e75-0c4aa5135195"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(g, y):\n",
    "    \"Computes the objective function.\"\n",
    "    labs = np.asarray(y, dtype=float).flatten()\n",
    "    posind = np.where(labs==1)\n",
    "    negind = np.where(labs==0)\n",
    "    return -np.log(g[posind, :]).sum() - np.log(1-g[negind, :]).sum()"
   ],
   "id": "f59382f3-4ff7-4791-8ec1-6ce953e65747"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As normal, we would like to minimize this objective. This can be done by\n",
    "differentiating with respect to the parameters of our prediction\n",
    "function, $\\pi(\\mathbf{ x};\\mathbf{ w})$, for optimisation. The gradient\n",
    "of the likelihood with respect to $\\pi(\\mathbf{ x};\\mathbf{ w})$ is of\n",
    "the form, $$\n",
    "\\frac{\\text{d}E(\\mathbf{ w})}{\\text{d}\\mathbf{ w}} = -\\sum_{i=1}^n\n",
    "\\frac{y_i}{g\\left(\\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x})\\right)}\\frac{\\text{d}g(f_i)}{\\text{d}f_i}\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}_i) +  \\sum_{i=1}^n\n",
    "\\frac{1-y_i}{1-g\\left(\\mathbf{ w}^\\top\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x})\\right)}\\frac{\\text{d}g(f_i)}{\\text{d}f_i}\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}_i)\n",
    "$$ where we used the chain rule to develop the derivative in terms of\n",
    "$\\frac{\\text{d}g(f_i)}{\\text{d}f_i}$, which is the gradient of the\n",
    "inverse link function (in our case the gradient of the sigmoid\n",
    "function).\n",
    "\n",
    "So the objective function now depends on the gradient of the inverse\n",
    "link function, as well as the likelihood depends on the gradient of the\n",
    "inverse link function, as well as the gradient of the log likelihood,\n",
    "and naturally the gradient of the argument of the inverse link function\n",
    "with respect to the parameters, which is simply\n",
    "$\\boldsymbol{ \\phi}(\\mathbf{ x}_i)$.\n",
    "\n",
    "The only missing term is the gradient of the inverse link function. For\n",
    "the sigmoid squashing function we have, $$\\begin{align*}\n",
    "g(f_i) &= \\frac{1}{1+\\exp(-f_i)}\\\\\n",
    "&=(1+\\exp(-f_i))^{-1}\n",
    "\\end{align*}$$ and the gradient can be computed as $$\\begin{align*}\n",
    "\\frac{\\text{d}g(f_i)}{\\text{d} f_i} & =\n",
    "\\exp(-f_i)(1+\\exp(-f_i))^{-2}\\\\\n",
    "& = \\frac{1}{1+\\exp(-f_i)}\n",
    "\\frac{\\exp(-f_i)}{1+\\exp(-f_i)} \\\\\n",
    "& = g(f_i) (1-g(f_i))\n",
    "\\end{align*}$$ so the full gradient can be written down as $$\n",
    "\\frac{\\text{d}E(\\mathbf{ w})}{\\text{d}\\mathbf{ w}} = -\\sum_{i=1}^n\n",
    "y_i\\left(1-g\\left(\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x})\\right)\\right)\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}_i) +  \\sum_{i=1}^n\n",
    "(1-y_i)\\left(g\\left(\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x})\\right)\\right)\n",
    "\\boldsymbol{ \\phi}(\\mathbf{ x}_i).\n",
    "$$"
   ],
   "id": "fe1d9273-2b60-41cb-92f4-a2c328dc46b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "2e10704c-c79b-4164-a83e-36af545edb5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(g, Phi, y):\n",
    "    \"Generates the gradient of the parameter vector.\"\n",
    "    labs = np.asarray(y, dtype=float).flatten()\n",
    "    posind = np.where(labs==1)\n",
    "    dw = -(Phi[posind]*(1-g[posind])).sum(0)\n",
    "    negind = np.where(labs==0 )\n",
    "    dw += (Phi[negind]*g[negind]).sum(0)\n",
    "    return dw[:, None]"
   ],
   "id": "62affa82-a0ee-4b18-a9e0-7bd35147d09b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of the Function\n",
    "\n",
    "Reorganizing the gradient to find a stationary point of the function\n",
    "with respect to the parameters $\\mathbf{ w}$ turns out to be impossible.\n",
    "Optimization has to proceed by *numerical methods*. Options include the\n",
    "multidimensional variant of [Newton’s\n",
    "method](http://en.wikipedia.org/wiki/Newton%27s_method) or [gradient\n",
    "based optimization\n",
    "methods](http://en.wikipedia.org/wiki/Gradient_method) like we used for\n",
    "optimizing matrix factorization for the movie recommender system. We\n",
    "recall from matrix factorization that, for large data, *stochastic\n",
    "gradient descent* or the Robbins Munro (Robbins and Monro, 1951)\n",
    "optimization procedure worked best for function minimization."
   ],
   "id": "db6b0587-f2d4-40ca-aca1-d6ea08f29372"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Prediction of Malaria Incidence in Uganda\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_health/includes/malaria-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_health/includes/malaria-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip7\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Martin Mubangizi\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://mlatcl.github.io/advds/./slides/diagrams//people/martin-mubangizi.png\" clip-path=\"url(#clip7)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip8\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Ricardo Andrade Pacheco\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://mlatcl.github.io/advds/./slides/diagrams//people/ricardo-andrade-pacheco.png\" clip-path=\"url(#clip8)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip9\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "John Quinn\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://mlatcl.github.io/advds/./slides/diagrams//people/john-quinn.jpg\" clip-path=\"url(#clip9)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "As an example of using Gaussian process models within the full pipeline\n",
    "from data to decsion, we’ll consider the prediction of Malaria incidence\n",
    "in Uganda. For the purposes of this study malaria reports come in two\n",
    "forms, HMIS reports from health centres and Sentinel data, which is\n",
    "curated by the WHO. There are limited sentinel sites and many HMIS\n",
    "sites.\n",
    "\n",
    "The work is from Ricardo Andrade Pacheco’s PhD thesis, completed in\n",
    "collaboration with John Quinn and Martin Mubangizi (Andrade-Pacheco et\n",
    "al., 2014; Mubangizi et al., 2014). John and Martin were initally from\n",
    "the AI-DEV group from the University of Makerere in Kampala and more\n",
    "latterly they were based at UN Global Pulse in Kampala. You can see the\n",
    "work summarized on the UN Global Pulse [disease outbreaks project site\n",
    "here](https://diseaseoutbreaks.unglobalpulse.net/uganda/).\n",
    "\n",
    "-   See [UN Global Pulse Disease Outbreaks\n",
    "    Site](https://diseaseoutbreaks.unglobalpulse.net/uganda/)\n",
    "\n",
    "Malaria data is spatial data. Uganda is split into districts, and health\n",
    "reports can be found for each district. This suggests that models such\n",
    "as conditional random fields could be used for spatial modelling, but\n",
    "there are two complexities with this. First of all, occasionally\n",
    "districts split into two. Secondly, sentinel sites are a specific\n",
    "location within a district, such as Nagongera which is a sentinel site\n",
    "based in the Tororo district.\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/uganda-districts-2006.png\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>Ugandan districts. Data SRTM/NASA from\n",
    "<https://dds.cr.usgs.gov/srtm/version2_1>.</i>\n",
    "\n",
    "(Andrade-Pacheco et al., 2014; Mubangizi et al., 2014)\n",
    "\n",
    "The common standard for collecting health data on the African continent\n",
    "is from the Health management information systems (HMIS). However, this\n",
    "data suffers from missing values (Gething et al., 2006) and diagnosis of\n",
    "diseases like typhoid and malaria may be confounded.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/Tororo_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The Tororo district, where the sentinel site, Nagongera, is\n",
    "located.</i>\n",
    "\n",
    "[World Health Organization Sentinel Surveillance\n",
    "systems](https://www.who.int/immunization/monitoring_surveillance/burden/vpd/surveillance_type/sentinel/en/)\n",
    "are set up “when high-quality data are needed about a particular disease\n",
    "that cannot be obtained through a passive system”. Several sentinel\n",
    "sites give accurate assessment of malaria disease levels in Uganda,\n",
    "including a site in Nagongera.\n",
    "\n",
    "<img class=\"negate\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/sentinel_nagongera.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>Sentinel and HMIS data along with rainfall and temperature\n",
    "for the Nagongera sentinel station in the Tororo district.</i>\n",
    "\n",
    "In collaboration with the AI Research Group at Makerere we chose to\n",
    "investigate whether Gaussian process models could be used to assimilate\n",
    "information from these two different sources of disease informaton.\n",
    "Further, we were interested in whether local information on rainfall and\n",
    "temperature could be used to improve malaria estimates.\n",
    "\n",
    "The aim of the project was to use WHO Sentinel sites, alongside rainfall\n",
    "and temperature, to improve predictions from HMIS data of levels of\n",
    "malaria.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/Mubende_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The Mubende District.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/mubende.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Prediction of malaria incidence in Mubende.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//gpss/1157497_513423392066576_1845599035_n.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The project arose out of the Gaussian process summer school\n",
    "held at Makerere in Kampala in 2013. The school led, in turn, to the\n",
    "Data Science Africa initiative.</i>"
   ],
   "id": "193cb59a-54ca-4916-980e-e26d6af3d827"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Warning Systems\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/Kabarole_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The Kabarole district in Uganda.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/kabarole.gif\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>Estimate of the current disease situation in the Kabarole\n",
    "district over time. Estimate is constructed with a Gaussian process with\n",
    "an additive covariance funciton.</i>\n",
    "\n",
    "Health monitoring system for the Kabarole district. Here we have fitted\n",
    "the reports with a Gaussian process with an additive covariance\n",
    "function. It has two components, one is a long time scale component (in\n",
    "red above) the other is a short time scale component (in blue).\n",
    "\n",
    "Monitoring proceeds by considering two aspects of the curve. Is the blue\n",
    "line (the short term report signal) above the red (which represents the\n",
    "long term trend? If so we have higher than expected reports. If this is\n",
    "the case *and* the gradient is still positive (i.e. reports are going\n",
    "up) we encode this with a *red* color. If it is the case and the\n",
    "gradient of the blue line is negative (i.e. reports are going down) we\n",
    "encode this with an *amber* color. Conversely, if the blue line is below\n",
    "the red *and* decreasing, we color *green*. On the other hand if it is\n",
    "below red but increasing, we color *yellow*.\n",
    "\n",
    "This gives us an early warning system for disease. Red is a bad\n",
    "situation getting worse, amber is bad, but improving. Green is good and\n",
    "getting better and yellow good but degrading.\n",
    "\n",
    "Finally, there is a gray region which represents when the scale of the\n",
    "effect is small.\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//health/monitor.gif\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>The map of Ugandan districts with an overview of the Malaria\n",
    "situation in each district.</i>\n",
    "\n",
    "These colors can now be observed directly on a spatial map of the\n",
    "districts to give an immediate impression of the current status of the\n",
    "disease across the country."
   ],
   "id": "904f17eb-040b-40e2-bbe5-f9ed8fda0cde"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-overview.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-overview.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Classical statistical models and simple machine learning models have a\n",
    "great deal in common. The main difference between the fields is\n",
    "philosophical. Machine learning practitioners are typically more\n",
    "concerned with the quality of prediciton (e.g. measured by ROC curve)\n",
    "while statisticians tend to focus more on the interpretability of the\n",
    "model and the validity of any decisions drawn from that interpretation.\n",
    "For example, a statistical model may be used to validate whether a large\n",
    "scale intervention (such as the mass provision of mosquito nets) has had\n",
    "a long term effect on disease (such as malaria). In this case one of the\n",
    "covariates is likely to be the provision level of nets in a particular\n",
    "region. The response variable would be the rate of malaria disease in\n",
    "the region. The parmaeter, $\\beta_1$ associated with that covariate will\n",
    "demonstrate a positive or negative effect which would be validated in\n",
    "answering the question. The focus in statistics would be less on the\n",
    "accuracy of the response variable and more on the validity of the\n",
    "interpretation of the effect variable, $\\beta_1$.\n",
    "\n",
    "A machine learning practitioner on the other hand would typically denote\n",
    "the parameter $w_1$, instead of $\\beta_1$ and would only be interested\n",
    "in the output of the prediction function, $f(\\cdot)$ rather than the\n",
    "parameter itself. The general formalism of the prediction function\n",
    "allows for *non-linear* models. In machine learning, the emphasis on\n",
    "prediction over interpretability means that non-linear models are often\n",
    "used. The parameters, $\\mathbf{w}$, are a means to an end (good\n",
    "prediction) rather than an end in themselves (interpretable).\n",
    "\n",
    "<!-- No slide titles in this context -->"
   ],
   "id": "057df4d6-cfdd-43e3-af5b-e94a293d5bda"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFace\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-face.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-face.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//deepface_neg.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>The DeepFace architecture (Taigman et al., 2014), visualized\n",
    "through colors to represent the functional mappings at each layer. There\n",
    "are 120 million parameters in the model.</i>\n",
    "\n",
    "The DeepFace architecture (Taigman et al., 2014) consists of layers that\n",
    "deal with *translation* invariances, known as convolutional layers.\n",
    "These layers are followed by three locally-connected layers and two\n",
    "fully-connected layers. Color illustrates feature maps produced at each\n",
    "layer. The neural network includes more than 120 million parameters,\n",
    "where more than 95% come from the local and fully connected layers."
   ],
   "id": "c2020f30-852f-4950-8765-ea2df0b63e59"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning as Pinball\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-as-pinball.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-as-pinball.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//576px-Early_Pinball.jpg\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>Deep learning models are composition of simple functions. We\n",
    "can think of a pinball machine as an analogy. Each layer of pins\n",
    "corresponds to one of the layers of functions in the model. Input data\n",
    "is represented by the location of the ball from left to right when it is\n",
    "dropped in from the top. Output class comes from the position of the\n",
    "ball as it leaves the pins at the bottom.</i>\n",
    "\n",
    "Sometimes deep learning models are described as being like the brain, or\n",
    "too complex to understand, but one analogy I find useful to help the\n",
    "gist of these models is to think of them as being similar to early pin\n",
    "ball machines.\n",
    "\n",
    "In a deep neural network, we input a number (or numbers), whereas in\n",
    "pinball, we input a ball.\n",
    "\n",
    "Think of the location of the ball on the left-right axis as a single\n",
    "number. Our simple pinball machine can only take one number at a time.\n",
    "As the ball falls through the machine, each layer of pins can be thought\n",
    "of as a different layer of ‘neurons’. Each layer acts to move the ball\n",
    "from left to right.\n",
    "\n",
    "In a pinball machine, when the ball gets to the bottom it might fall\n",
    "into a hole defining a score, in a neural network, that is equivalent to\n",
    "the decision: a classification of the input object.\n",
    "\n",
    "An image has more than one number associated with it, so it is like\n",
    "playing pinball in a *hyper-space*.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//pinball001.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>At initialization, the pins, which represent the parameters\n",
    "of the function, aren’t in the right place to bring the balls to the\n",
    "correct decisions.</i>\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//pinball002.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>After learning the pins are now in the right place to bring\n",
    "the balls to the correct decisions.</i>\n",
    "\n",
    "Learning involves moving all the pins to be in the correct position, so\n",
    "that the ball ends up in the right place when it’s fallen through the\n",
    "machine. But moving all these pins in hyperspace can be difficult.\n",
    "\n",
    "In a hyper-space you have to put a lot of data through the machine for\n",
    "to explore the positions of all the pins. Even when you feed many\n",
    "millions of data points through the machine, there are likely to be\n",
    "regions in the hyper-space where no ball has passed. When future test\n",
    "data passes through the machine in a new route unusual things can\n",
    "happen.\n",
    "\n",
    "*Adversarial examples* exploit this high dimensional space. If you have\n",
    "access to the pinball machine, you can use gradient methods to find a\n",
    "position for the ball in the hyper space where the image looks like one\n",
    "thing, but will be classified as another.\n",
    "\n",
    "Probabilistic methods explore more of the space by considering a range\n",
    "of possible paths for the ball through the machine. This helps to make\n",
    "them more data efficient and gives some robustness to adversarial\n",
    "examples."
   ],
   "id": "c0708ec8-ae29-4ed8-80d5-a6cb0bcd2a85"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Large Language Models?"
   ],
   "id": "6e5716d2-f443-49f4-98c3-180ebf9f4c57"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Conversations\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-probability.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-probability.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//ai/anne-probability-conversation.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The focus so far has been on reducing uncertainty to a few\n",
    "representative values and sharing numbers with human beings. We forget\n",
    "that most people can be confused by basic probabilities for example the\n",
    "prosecutor’s fallacy.</i>\n",
    "\n",
    "In practice we know that probabilities can be very unintuitive, for\n",
    "example in court there is a fallacy known as the “prosecutor’s fallacy”\n",
    "that confuses conditional probabilities. This can cause problems in jury\n",
    "trials (Thompson, 1989)."
   ],
   "id": "8daa3ae2-c8ca-4181-ab7e-b059664be0c7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Large Language Models?\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-are-large-language-models.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/what-are-large-language-models.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "608d6664-6323-4a06-a0cc-bfbf0d47a6a0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MONIAC\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "[The MONIAC](https://en.wikipedia.org/wiki/MONIAC) was an analogue\n",
    "computer designed to simulate the UK economy. Analogue comptuers work\n",
    "through analogy, the analogy in the MONIAC is that both money and water\n",
    "flow. The MONIAC exploits this through a system of tanks, pipes, valves\n",
    "and floats that represent the flow of money through the UK economy.\n",
    "Water flowed from the treasury tank at the top of the model to other\n",
    "tanks representing government spending, such as health and education.\n",
    "The machine was initially designed for teaching support but was also\n",
    "found to be a useful economic simulator. Several were built and today\n",
    "you can see the original at Leeds Business School, there is also one in\n",
    "the London Science Museum and one [in the Unisversity of Cambridge’s\n",
    "economics\n",
    "faculty](https://www.econ.cam.ac.uk/economics-alumni/drip-down-economics-phillips-machine).\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//simulation/Phillips_and_MONIAC_LSE.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Bill Phillips and his MONIAC (completed in 1949). The machine\n",
    "is an analogue computer designed to simulate the workings of the UK\n",
    "economy.</i>\n",
    "\n",
    "See Lawrence (2024) MONIAC p. 232-233, 266, 343.\n",
    "\n",
    "But if we can avoid the pitfalls of counterfeit people, this also offers\n",
    "us an opportunity to *psychologically represent*\n",
    "(**Heider:interpersonal58?**) the machine in a manner where humans can\n",
    "communicate without special training. This in turn offers the\n",
    "opportunity to overcome the challenge of *intellectual debt*.\n",
    "\n",
    "Despite the lack of interpretability of machine learning models, they\n",
    "allow us access to what the machine is doing in a way that bypasses many\n",
    "of the traditional techniques developed in statistics. But understanding\n",
    "this new route for access is a major new challenge."
   ],
   "id": "915d035d-8c54-4d28-b6a7-4c3efa4e87ca"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The Human-Analogue Machine or HAM therefore provides a route through\n",
    "which we could better understand our world through improving the way we\n",
    "interact with machines.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//data-science/new-flow-of-information004.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The trinity of human, data, and computer, and highlights the\n",
    "modern phenomenon. The communication channel between computer and data\n",
    "now has an extremely high bandwidth. The channel between human and\n",
    "computer and the channel between data and human is narrow. New direction\n",
    "of information flow, information is reaching us mediated by the\n",
    "computer. The focus on classical statistics reflected the importance of\n",
    "the direct communication between human and data. The modern challenges\n",
    "of data science emerge when that relationship is being mediated by the\n",
    "machine.</i>\n",
    "\n",
    "The HAM can provide an interface between the digital computer and the\n",
    "human allowing humans to work closely with computers regardless of their\n",
    "understandin gf the more technical parts of software engineering.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//data-science/new-flow-of-information-ham.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The HAM now sits between us and the traditional digital\n",
    "computer.</i>\n",
    "\n",
    "Of course this route provides new routes for manipulation, new ways in\n",
    "which the machine can undermine our autonomy or exploit our cognitive\n",
    "foibles. The major challenge we face is steering between these worlds\n",
    "where we gain the advantage of the computer’s bandwidth without\n",
    "undermining our culture and individual autonomy.\n",
    "\n",
    "See Lawrence (2024) human-analogue machine (HAMs) p. 343-347, 359-359,\n",
    "365-368."
   ],
   "id": "d7472fb2-6858-4e9c-aab1-1e0f590dc7ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity in Action\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "As an exercise in understanding complexity, watch the following video.\n",
    "You will see the basketball being bounced around, and the players\n",
    "moving. Your job is to count the passes of those dressed in white and\n",
    "ignore those of the individuals dressed in black."
   ],
   "id": "a2af9003-46e0-4323-8aaa-ca7f17c9af8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('vJG698U2Mvo')"
   ],
   "id": "a0eed049-4e3a-4328-8ddc-3d1677a43f1c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Daniel Simon’s famous illusion “monkey business”. Focus on\n",
    "the movement of the ball distracts the viewer from seeing other aspects\n",
    "of the image.</i>\n",
    "\n",
    "In a classic study Simons and Chabris (1999) ask subjects to count the\n",
    "number of passes of the basketball between players on the team wearing\n",
    "white shirts. Fifty percent of the time, these subjects don’t notice the\n",
    "gorilla moving across the scene.\n",
    "\n",
    "The phenomenon of inattentional blindness is well known, e.g in their\n",
    "paper Simons and Charbris quote the Hungarian neurologist, Rezsö Bálint,\n",
    "\n",
    "> It is a well-known phenomenon that we do not notice anything happening\n",
    "> in our surroundings while being absorbed in the inspection of\n",
    "> something; focusing our attention on a certain object may happen to\n",
    "> such an extent that we cannot perceive other objects placed in the\n",
    "> peripheral parts of our visual field, although the light rays they\n",
    "> emit arrive completely at the visual sphere of the cerebral cortex.\n",
    ">\n",
    "> Rezsö Bálint 1907 (translated in Husain and Stein 1988, page 91)\n",
    "\n",
    "When we combine the complexity of the world with our relatively low\n",
    "bandwidth for information, problems can arise. Our focus on what we\n",
    "perceive to be the most important problem can cause us to miss other\n",
    "(potentially vital) contextual information.\n",
    "\n",
    "This phenomenon is known as selective attention or ‘inattentional\n",
    "blindness’."
   ],
   "id": "b535cc41-a3e8-4608-beb0-e45fd9ae49fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('_oGAzq5wM_Q')"
   ],
   "id": "356041be-77eb-4bbf-a3c3-ccba321ead80"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>For a longer talk on inattentional bias from Daniel Simons\n",
    "see this video.</i>"
   ],
   "id": "f26a2ff2-a4cc-4b32-ac30-8fc01d7c7c2f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selective Attention Bias\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-selection-attention-bias.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-selection-attention-bias.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "We are going to see how inattention biases can play out in data analysis\n",
    "by going through a simple example. The analysis involves body mass index\n",
    "and activity information."
   ],
   "id": "8be38daa-ded1-44e4-ad34-67edd9753c8a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hypothesis as a Liability\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/hypothesis-as-a-liability.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/hypothesis-as-a-liability.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "This analysis is from an article titled “A Hypothesis as a Liability”\n",
    "(Yanai and Lercher, 2020), they start their article with the following\n",
    "quite from Herman Hesse.\n",
    "\n",
    "> ” ‘When someone seeks,’ said Siddhartha, ‘then it easily happens that\n",
    "> his eyes see only the thing that he seeks, and he is able to find\n",
    "> nothing, to take in nothing. \\[…\\] Seeking means: having a goal. But\n",
    "> finding means: being free, being open, having no goal.’ ”\n",
    ">\n",
    "> Hermann Hesse\n",
    "\n",
    "Their idea is that having a hypothesis can constrain our thinking.\n",
    "However, in answer to their paper Felin et al. (2021) argue that some\n",
    "form of hypothesis is always necessary, suggesting that a hypothesis\n",
    "*can* be a liability\n",
    "\n",
    "My view is captured in the introductory chapter to an edited volume on\n",
    "computational systems biology that I worked on with Mark Girolami,\n",
    "Magnus Rattray and Guido Sanguinetti.\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//data-science/licsb-popper-quote.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Quote from Lawrence (2010) highlighting the importance of\n",
    "interaction between data and hypothesis.</i>\n",
    "\n",
    "Popper nicely captures the interaction between hypothesis and data by\n",
    "relating it to the chicken and the egg. The important thing is that\n",
    "these two co-evolve."
   ],
   "id": "ae538a3f-9ad5-40c2-9c4a-d7fcc46b5749"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number Theatre\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/number-data-theatre.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/number-data-theatre.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Unfortunately, we don’t always have time to wait for this process to\n",
    "converge to an answer we can all rely on before a decision is required.\n",
    "\n",
    "Not only can we be misled by data before a decision is made, but\n",
    "sometimes we can be misled by data to justify the making of a decision.\n",
    "David Spiegelhalter refers to the phenomenon of “Number Theatre” in a\n",
    "conversation with Andrew Marr from May 2020 on the presentation of data."
   ],
   "id": "4e247568-715e-4a7a-9278-cca43b4f751f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('9388XmWIHXg')"
   ],
   "id": "543560c0-b07c-4539-a956-71fe7fd934ac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Professor Sir David Spiegelhalter on Andrew Marr on 10th May\n",
    "2020 speaking about some of the challengers around data, data\n",
    "presentation, and decision making in a pandemic. David mentions number\n",
    "theatre at 9 minutes 10 seconds.</i>\n",
    "\n",
    "<!--includebbcvideo{p08csg28}-->"
   ],
   "id": "7a03a33e-f1e2-4c41-8f95-26683be1ca71"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Theatre\n",
    "\n",
    "Data Theatre exploits data inattention bias to present a particular view\n",
    "on events that may misrepresents through selective presentation.\n",
    "Statisticians are one of the few groups that are trained with a\n",
    "sufficient degree of data skepticism. But it can also be combatted\n",
    "through ensuring there are domain experts present, and that they can\n",
    "speak freely.\n",
    "\n",
    "<img src=\"https://mlatcl.github.io/advds/./slides/diagrams//business/data-theatre001.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The phenomenon of number theatre or *data theatre* was\n",
    "described by David Spiegelhalter and is nicely summarized by Martin\n",
    "Robbins in this sub-stack article\n",
    "<https://martinrobbins.substack.com/p/data-theatre-why-the-digital-dashboards>.</i>"
   ],
   "id": "222e1a1e-b04a-4e4f-b0de-85b766188acf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sir David Spiegelhalter\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/sir-david-spiegelhalter.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/sir-david-spiegelhalter.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<center>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip10\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "David Spiegelhalter\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://mlatcl.github.io/advds/./slides/diagrams//people/david-spiegelhalter.png\" clip-path=\"url(#clip10)\"/>\n",
    "\n",
    "</svg>\n",
    "</center>\n",
    "\n",
    "The statistician’s craft is based on humility in front of data and\n",
    "developing the appropriate skeptical thinking around conclusions from\n",
    "data. The best individual I’ve seen at conveying and developing that\n",
    "sense is Sir David Spiegelhalter."
   ],
   "id": "237c1ffc-339e-439a-9a50-2c01b1a9b34c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Art of Statistics\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-statistics.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-statistics.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//books/the-art-of-statistics.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[The Art of Statistics by David\n",
    "Spiegelhalter](https://www.amazon.co.uk/Art-Statistics-Learning-Pelican-Books-ebook/dp/B07HQDJD99)\n",
    "is an excellent read on the pitfalls of data interpretation.</i>\n",
    "\n",
    "*The Art of Statistics* (Spiegelhalter, 2019) brings important examples\n",
    "from statistics to life in an intelligent and entertaining way. It is\n",
    "highly readable and gives an opportunity to fast-track towards the\n",
    "important skill of data-skepticism that is the mark of a professional\n",
    "statistician."
   ],
   "id": "5cd64b8e-4d61-4400-8366-2fa74b7e4e94"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Art of Uncertainty\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-uncertainty.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-uncertainty.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "David has also released a new book that focusses on Uncertainty.\n",
    "\n",
    "<img class=\"\" src=\"https://mlatcl.github.io/advds/./slides/diagrams//books/the-art-of-uncertainty.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[The Art of Uncertainty by David\n",
    "Spiegelhalter](https://www.amazon.co.uk/Art-Uncertainty-Navigate-Chance-Ignorance/dp/0241658624).</i>\n",
    "\n",
    "See (Spiegelhalter, 2024)\n",
    "\n",
    "In today’s lecture we’ve drilled down further on a difficult aspect of\n",
    "data science. By focusing too much on the data and the technical\n",
    "challenges we face, we can forget the context. But to do data science\n",
    "well, we must not forget the context of the data. We need to pay\n",
    "attention to domain experts and introduce their understanding to our\n",
    "analysis. Above all we must not forget that data is almost always (in\n",
    "the end) about people."
   ],
   "id": "6ac04f45-23a7-432b-b3d1-15d65d1f05a5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "-   Section 5.2.2 up to pg 182 of Rogers and Girolami (2011)"
   ],
   "id": "7279b723-33f8-4fd5-9b4d-7e8d07cf824f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ],
   "id": "e443f311-bce3-4acc-a043-fb74078599df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!\n",
    "\n",
    "For more information on these subjects and more you might want to check\n",
    "the following resources.\n",
    "\n",
    "-   book: [The Atomic\n",
    "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
    "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
    "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
    "-   newspaper: [Guardian Profile\n",
    "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
    "-   blog:\n",
    "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
   ],
   "id": "a6d9d956-459b-4fd4-8e04-f7544672eb45"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andrade-Pacheco, R., Mubangizi, M., Quinn, J., Lawrence, N.D., 2014.\n",
    "Consistent mapping of government malaria records across a changing\n",
    "territory delimitation. Malaria Journal 13.\n",
    "<https://doi.org/10.1186/1475-2875-13-S1-P5>\n",
    "\n",
    "Felin, T., Koenderink, J., Krueger, J.I., Noble, D., Ellis, G.F.R.,\n",
    "2021. The data-hypothesis relationship. Genome Biology 22.\n",
    "<https://doi.org/10.1186/s13059-021-02276-4>\n",
    "\n",
    "Gething, P.W., Noor, A.M., Gikandi, P.W., Ogara, E.A.A., Hay, S.I.,\n",
    "Nixon, M.S., Snow, R.W., Atkinson, P.M., 2006. Improving imperfect data\n",
    "from health management information systems in Africa using space–time\n",
    "geostatistics. PLoS Medicine 3.\n",
    "<https://doi.org/10.1371/journal.pmed.0030271>\n",
    "\n",
    "Lawrence, N.D., 2024. [The atomic human: Understanding ourselves in the\n",
    "age of\n",
    "AI](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248).\n",
    "Allen Lane.\n",
    "\n",
    "Lawrence, N.D., 2010. Introduction to learning and inference in\n",
    "computational systems biology.\n",
    "\n",
    "Mubangizi, M., Andrade-Pacheco, R., Smith, M.T., Quinn, J., Lawrence,\n",
    "N.D., 2014. Malaria surveillance with multiple data sources using\n",
    "Gaussian process models, in: 1st International Conference on the Use of\n",
    "Mobile ICT in Africa.\n",
    "\n",
    "Robbins, H., Monro, S., 1951. A stochastic approximation method. Annals\n",
    "of Mathematical Statistics 22, 400–407.\n",
    "\n",
    "Rogers, S., Girolami, M., 2011. A first course in machine learning. CRC\n",
    "Press.\n",
    "\n",
    "Simons, D.J., Chabris, C.F., 1999. Gorillas in our midst: Sustained\n",
    "inattentional blindness for dynamic events. Perception 28, 1059–1074.\n",
    "<https://doi.org/10.1068/p281059>\n",
    "\n",
    "Spiegelhalter, D.J., 2024. The art of uncertainty. Pelican.\n",
    "\n",
    "Spiegelhalter, D.J., 2019. The art of statistics. Pelican.\n",
    "\n",
    "Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. DeepFace: Closing\n",
    "the gap to human-level performance in face verification, in: Proceedings\n",
    "of the IEEE Computer Society Conference on Computer Vision and Pattern\n",
    "Recognition. <https://doi.org/10.1109/CVPR.2014.220>\n",
    "\n",
    "Thompson, W.C., 1989. [Are juries competent to evaluate statistical\n",
    "evidence?](http://www.jstor.org/stable/1191906) Law and Contemporary\n",
    "Problems 52, 9–41.\n",
    "\n",
    "Wiener, N., 1948. Cybernetics: Control and communication in the animal\n",
    "and the machine. mitp, Cambridge, MA.\n",
    "\n",
    "Yanai, I., Lercher, M., 2020. A hypothesis is a liability. Genome\n",
    "Biology 21."
   ],
   "id": "24021c70-18df-4428-9137-af5fc4e7858a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
