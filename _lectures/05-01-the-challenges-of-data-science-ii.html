---
title: "Data Science Challenges II"
venue: "LT2, William Gates Building"
abstract: "<p>In this lecture we continue our exploration of data
science challenges.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_advds/the-challenges-of-data-science-ii.md
date: 2023-11-03
published: 2023-11-03
time: "10:00"
week: 5
session: 1
featured_image: assets/images/the-challenges-of-data-science-ii.png
reveal: 05-01-the-challenges-of-data-science-ii.slides.html
transition: None
youtube: "jdrw3kW0J18"
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h2 id="complexity-in-action">Complexity in Action</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>As an exercise in understanding complexity, watch the following
video. You will see the basketball being bounced around, and the players
moving. Your job is to count the passes of those dressed in white and
ignore those of the individuals dressed in black.</p>
<div class="figure">
<div id="monkey-business-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/vJG698U2Mvo?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="monkey-business-magnify" class="magnify"
onclick="magnifyFigure(&#39;monkey-business&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="monkey-business-caption" class="caption-frame">
<p>Figure: Daniel Simon’s famous illusion “monkey business”. Focus on
the movement of the ball distracts the viewer from seeing other aspects
of the image.</p>
</div>
</div>
<p>In a classic study <span class="citation"
data-cites="Simons-gorillas99">Simons and Chabris (1999)</span> ask
subjects to count the number of passes of the basketball between players
on the team wearing white shirts. Fifty percent of the time, these
subjects don’t notice the gorilla moving across the scene.</p>
<p>The phenomenon of inattentional blindness is well known, e.g in their
paper Simons and Charbris quote the Hungarian neurologist, Rezsö
Bálint,</p>
<blockquote>
<p>It is a well-known phenomenon that we do not notice anything
happening in our surroundings while being absorbed in the inspection of
something; focusing our attention on a certain object may happen to such
an extent that we cannot perceive other objects placed in the peripheral
parts of our visual field, although the light rays they emit arrive
completely at the visual sphere of the cerebral cortex.</p>
<p>Rezsö Bálint 1907 (translated in Husain and Stein 1988, page 91)</p>
</blockquote>
<p>When we combine the complexity of the world with our relatively low
bandwidth for information, problems can arise. Our focus on what we
perceive to be the most important problem can cause us to miss other
(potentially vital) contextual information.</p>
<p>This phenomenon is known as selective attention or ‘inattentional
blindness’.</p>
<div class="figure">
<div id="daniel-simons-monkey-business-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/_oGAzq5wM_Q?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="daniel-simons-monkey-business-magnify" class="magnify"
onclick="magnifyFigure(&#39;daniel-simons-monkey-business&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="daniel-simons-monkey-business-caption" class="caption-frame">
<p>Figure: For a longer talk on inattentional bias from Daniel Simons
see this video.</p>
</div>
</div>
<h2 id="data-selective-attention-bias">Data Selective Attention
Bias</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-selection-attention-bias.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-selection-attention-bias.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>We are going to see how inattention biases can play out in data
analysis by going through a simple example. The analysis involves body
mass index and activity information.</p>
<h2 id="a-hypothesis-as-a-liability">A Hypothesis as a Liability</h2>
<p>This analysis is from an article titled “A Hypothesis as a Liability”
<span class="citation" data-cites="Yanai-hypothesis20">(Yanai and
Lercher, 2020)</span>, they start their article with the following quite
from Herman Hesse.</p>
<blockquote>
<p>“ ‘When someone seeks,’ said Siddhartha, ‘then it easily happens that
his eyes see only the thing that he seeks, and he is able to find
nothing, to take in nothing. […] Seeking means: having a goal. But
finding means: being free, being open, having no goal.’ ”</p>
<p>Hermann Hesse</p>
</blockquote>
<p>Their idea is that having a hypothesis can constrain our thinking.
However, in answer to their paper <span class="citation"
data-cites="Felin-data20">Felin et al. (2021)</span> argue that some
form of hypothesis is always necessary, suggesting that a hypothesis
<em>can</em> be a liability</p>
<p>My view is captured in the introductory chapter to an edited volume
on computational systems biology that I worked on with Mark Girolami,
Magnus Rattray and Guido Sanguinetti.</p>
<div class="figure">
<div id="licsb-popper-quote-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//data-science/licsb-popper-quote.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="licsb-popper-quote-magnify" class="magnify"
onclick="magnifyFigure(&#39;licsb-popper-quote&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="licsb-popper-quote-caption" class="caption-frame">
<p>Figure: Quote from <span class="citation"
data-cites="Lawrence:licsbintro10">Lawrence (2010)</span> highlighting
the importance of interaction between data and hypothesis.</p>
</div>
</div>
<p>Popper nicely captures the interaction between hypothesis and data by
relating it to the chicken and the egg. The important thing is that
these two co-evolve.</p>
<h2 id="number-theatre">Number Theatre</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/number-data-theatre.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/number-data-theatre.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Unfortunately, we don’t always have time to wait for this process to
converge to an answer we can all rely on before a decision is
required.</p>
<p>Not only can we be misled by data before a decision is made, but
sometimes we can be misled by data to justify the making of a decision.
David Spiegelhalter refers to the phenomenon of “Number Theatre” in a
conversation with Andrew Marr from May 2020 on the presentation of
data.</p>
<div class="figure">
<div id="david-andrew-marr-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/9388XmWIHXg?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="david-andrew-marr-magnify" class="magnify"
onclick="magnifyFigure(&#39;david-andrew-marr&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="david-andrew-marr-caption" class="caption-frame">
<p>Figure: Professor Sir David Spiegelhalter on Andrew Marr on 10th May
2020 speaking about some of the challengers around data, data
presentation, and decision making in a pandemic. David mentions number
theatre at 9 minutes 10 seconds.</p>
</div>
</div>
<!--includebbcvideo{p08csg28}-->
<h2 id="data-theatre">Data Theatre</h2>
<p>Data Theatre exploits data inattention bias to present a particular
view on events that may misrepresents through selective presentation.
Statisticians are one of the few groups that are trained with a
sufficient degree of data skepticism. But it can also be combatted
through ensuring there are domain experts present, and that they can
speak freely.</p>
<div class="figure">
<div id="data-theatre-001-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/advds/./slides/diagrams//business/data-theatre001.svg" width="60%" style=" ">
</object>
</div>
<div id="data-theatre-001-magnify" class="magnify"
onclick="magnifyFigure(&#39;data-theatre-001&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="data-theatre-001-caption" class="caption-frame">
<p>Figure: The phenomenon of number theatre or <em>data theatre</em> was
described by David Spiegelhalter and is nicely summarized by Martin
Robbins in this sub-stack article <a
href="https://martinrobbins.substack.com/p/data-theatre-why-the-digital-dashboards"
class="uri">https://martinrobbins.substack.com/p/data-theatre-why-the-digital-dashboards</a>.</p>
</div>
</div>
<h1 id="the-art-of-statistics">The Art of Statistics</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-statistics.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-art-of-statistics.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The statistician’s craft is based on humility in front of data and
developing the appropriate skeptical thinking around conclusions from
data. The best book I’ve seen for developing that sense is Sir David
Spiegelhalter’s <em>Art of Statistics</em>.</p>
<center>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
David Spiegelhalter
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/advds/./slides/diagrams//people/david-spiegelhalter.png" clip-path="url(#clip0)"/>
</svg>
</center>
<div class="figure">
<div id="art-of-statistics-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//books/the-art-of-statistics.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="art-of-statistics-magnify" class="magnify"
onclick="magnifyFigure(&#39;art-of-statistics&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="art-of-statistics-caption" class="caption-frame">
<p>Figure: <a
href="https://www.amazon.co.uk/Art-Statistics-Learning-Pelican-Books-ebook/dp/B07HQDJD99">The
Art of Statistics by David Spiegelhalter</a> is an excellent read on the
pitfalls of data interpretation.</p>
</div>
</div>
<p>David’s book <span class="citation"
data-cites="Spiegelhalter-art19">(Spiegelhalter, 2019)</span> brings
important examples from statistics to life in an intelligent and
entertaining way. It is highly readable and gives an opportunity to
fast-track towards the important skill of data-skepticism that is the
mark of a professional statistician.</p>
<h2 id="societal-effects">Societal Effects</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/societal-effects.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/societal-effects.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>We have already seen the effects of this changed dynamic in biology
and computational biology. Improved sensorics have led to the new
domains of transcriptomics, epigenomics, and ‘rich phenomics’ as well as
considerably augmenting our capabilities in genomics.</p>
<p>Biologists have had to become data-savvy, they require a rich
understanding of the available data resources and need to assimilate
existing data sets in their hypothesis generation as well as their
experimental design. Modern biology has become a far more quantitative
science, but the quantitativeness has required new methods developed in
the domains of <em>computational biology</em> and
<em>bioinformatics</em>.</p>
<p>There is also great promise for personalized health, but in health
the wide data-sharing that has underpinned success in the computational
biology community is much harder to carry out.</p>
<p>We can expect to see these phenomena reflected in wider society.
Particularly as we make use of more automated decision making based only
on data. This is leading to a requirement to better understand our own
subjective biases to ensure that the human to computer interface allows
domain experts to assimilate data driven conclusions in a well
calibrated manner. This is particularly important where medical
treatments are being prescribed. It also offers potential for different
kinds of medical intervention. More subtle interventions are possible
when the digital environment is able to respond to users in an bespoke
manner. This has particular implications for treatment of mental health
conditions.</p>
<p>The main phenomenon we see across the board is the shift in dynamic
from the direct pathway between human and data, as traditionally
mediated by classical statistics, to a new flow of information via the
computer. This change of dynamics gives us the modern and emerging
domain of <em>data science</em>, where the interactions between human
and data are mediated by the machine.</p>
<h2 id="challenges">Challenges</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/three-data-science-challenges.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/three-data-science-challenges.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The field of data science is rapidly evolving. Different
practitioners from different domains have their own perspectives. We
identify three broad challenges that are emerging. Challenges which have
not been addressed in the traditional sub-domains of data science. The
challenges have social implications but require technological advance
for their solutions.</p>
<ol type="1">
<li>Paradoxes of the Data Society</li>
<li>Quantifying the Value of Data</li>
<li>Privacy, loss of control, marginalization</li>
</ol>
<p>You can also check this blog post on <a
href="http://inverseprobability.com/2016/07/01/data-science-challenges">Three
Data Science Challenges</a>.</p>
<h2 id="paradoxes-of-data-society">Paradoxes of Data Society</h2>
<div class="figure">
<div id="pooh-rabbit-hoosh-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//ml/E.-H.-Shepard_Two-ink-drawings-from-The-House-at-Pooh-Corner-I_.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="pooh-rabbit-hoosh-magnify" class="magnify"
onclick="magnifyFigure(&#39;pooh-rabbit-hoosh&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="pooh-rabbit-hoosh-caption" class="caption-frame">
<p>Figure: Rabbit and Pooh watch the result of Pooh’s hooshing idea to
move Eeyore towards the shore.</p>
</div>
</div>
<blockquote>
<p>When you are a Bear of Very Little Brain, and you Think of Things,
you find sometimes that a Thing which seemed very Thingish inside you is
quite different when it gets out into the open and has other people
looking at it.</p>
<p>A.A. Milne as Winnie-the-Pooh in <em>The House at Pooh Corner</em>,
1928</p>
</blockquote>
<p>This comment from Pooh bear comes just as he’s tried to rescue his
donkey friend, Eeyore, from a river by dropping a large stone on him
from a bridge. Pooh’s idea had been to create a wave to push the donkey
to the shore, a process that Pooh’s rabbit friend calls “hooshing”.</p>
<p>Hooshing is a technique many children will have tried to retrieve a
ball from a river. It can work, so Pooh’s idea wasn’t a bad one, but the
challenge he faced was in its execution. Pooh aimed to the side of
Eeyore, unfortunately the stone fell directly on the stuffed donkey. But
where is Laplace’s demon in hooshing? Just as we can talk about Gliders
and Loafers in Conway’s Game of Life, we talk about stones and donkeys
in our Universe. Pooh’s prediction that he can hoosh the donkey with the
stone is not based on the Theory, it comes from observing the way
objects interact in the actual Universe. Pooh is like the mice in
Douglas Adams’s Earth. He is observing his environment. He looks for
patterns in that environment. Pooh then borrows the computation that the
Universe has already done for us. He has seen similar situations before,
perhaps he once used a stone to hoosh a ball. He is then generalising
from these previous circumstances to suggest that he can also hoosh the
donkey. Despite being a bear of little brain, like the mice on Adams’s
Earth, Pooh can answer questions about his universe by observing the
results of the Theory of Everything playing out around him.</p>
<h2 id="the-big-data-paradox">The Big Data Paradox</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/big-data-paradox.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/big-data-paradox.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The big data paradox is the modern phenomenon of “as we collect more
data, we understand less”. It is emerging in several domains, political
polling, characterization of patients for trials data, monitoring
twitter for political sentiment.</p>
<p>I like to think of the phenomenon as relating to the notion of “can’t
see the wood for the trees”. Classical statistics, with randomized
controlled trials, improved society’s understanding of data. It improved
our ability to monitor the forest, to consider population health, voting
patterns etc. It is critically dependent on active approaches to data
collection that deal with confounders. This data collection can be very
expensive.</p>
<p>In business today, it is still the gold standard, A/B tests are used
to understand the effect of an intervention on revenue or customer
capture or supply chain costs.</p>
<div class="figure">
<div id="gribskov-forest-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//Grib_skov.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gribskov-forest-magnify" class="magnify"
onclick="magnifyFigure(&#39;gribskov-forest&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gribskov-forest-caption" class="caption-frame">
<p>Figure: New beech leaves growing in the Gribskov Forest in the
northern part of Sealand, Denmark. Photo from wikimedia commons by
Malene Thyssen, <a href="http://commons.wikimedia.org/wiki/User:Malene"
class="uri">http://commons.wikimedia.org/wiki/User:Malene</a>.</p>
</div>
</div>
<p>The new phenomenon is <em>happenstance data</em>. Data that is not
actively collected with a question in mind. As a result, it can mislead
us. For example, if we assume the politics of active users of twitter is
reflective of the wider population’s politics, then we may be
misled.</p>
<p>However, this happenstance data often allows us to characterise a
particular individual to a high degree of accuracy. Classical statistics
was all about the forest, but big data can often become about the
individual tree. As a result we are misled about the situation.</p>
<p>The phenomenon is more dangerous, because our perception is that we
are characterizing the wider scenario with ever increasing accuracy.
Whereas we are just becoming distracted by detail that may or may not be
pertinent to the wider situation.</p>
<p>This is related to our limited bandwidth as humans, and the ease with
which we are distracted by detail. The
data-inattention-cognitive-bias.</p>
<h2 id="breadth-or-depth-paradox">Breadth or Depth Paradox</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/breadth-or-depth.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/breadth-or-depth.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The first challenge we’d like to highlight is the unusual paradoxes
of the data society. It is too early to determine whether these
paradoxes are fundamental or transient. Evidence for them is still
somewhat anecdotal, but they seem worthy of further attention.</p>
<h3 id="the-paradox-of-measurement">The Paradox of Measurement</h3>
<p>We are now able to quantify to a greater and greater degree the
actions of individuals in society, and this might lead us to believe
that social science, politics, economics are becoming quantifiable. We
are able to get a far richer characterization of the world around us.
Paradoxically it seems that as we measure more, we understand less.</p>
<p>How could this be possible? It may be that the greater preponderance
of data is making society itself more complex. Therefore traditional
approaches to measurement (e.g. polling by random sub sampling) are
becoming harder, for example due to more complex batch effects, a
greater stratification of society where it is more difficult to weigh
the various sub-populations correctly.</p>
<p>The end result is that we have a Curate’s egg of a society: it is
only ‘measured in parts’. Whether by examination of social media or
through polling we no longer obtain the overall picture that can be
necessary to obtain the depth of understanding we require.</p>
<p><a
href="http://www.theguardian.com/politics/2015/nov/13/new-research-general-election-polls-inaccurate">One
example of this phenomenon</a> is the 2015 UK election which polls had
as a tie and yet in practice was won by the Conservative party with a
seven point advantage. A post-election poll which was truly randomized
suggested that this lead was measurable, but pre-election polls are
conducted on line and via phone. These approaches can under represent
certain sectors. The challenge is that the truly randomized poll is
expensive and time consuming. In practice on line and phone polls are
usually weighted to reflect the fact that they are not truly randomized,
but in a rapidly evolving society the correct weights may move faster
than they can be tracked.</p>
<p>Another example is clinical trials. Once again they are the preserve
of randomized studies to verify the efficacy of the drug. But now,
rather than population becoming more stratified, it is the more
personalized nature of the drugs we wish to test. A targeted drug which
has efficacy in a sub-population may be harder to test due to difficulty
in recruiting the sub-population, the benefit of the drug is also for a
smaller sub-group, so expense of drug trials increases.</p>
<p>There are other less clear cut manifestations of this phenomenon. We
seem to rely increasingly on social media as a news source, or as a
indicator of opinion on a particular subject. But it is beholden to the
whims of a vocal minority.</p>
<p>Similar to the way we required more paper when we first developed the
computer, the solution is more <em>classical</em> statistics. We need to
do more work to verify the tentative conclusions we produce so that we
know that our new methodologies are effective.</p>
<p>As we increase the amount of data we acquire, we seem to be able to
get better at characterizing the actions of individuals, predicting how
they will behave. But we seem, somehow, to be becoming less capable at
understanding society. Somehow it seems that as we measure more, we
understand less.</p>
<p>That seems counter-intuitive. But perhaps the preponderance of data
is making society itself, or the way we measure society, somehow more
complex. And in turn, this means that traditional approaches to
measurement are failing. So when we realize we are getting better at
characterising individuals, perhaps we are only measuring society in
parts.</p>
<h2 id="breadth-vs-depth">Breadth vs Depth</h2>
<p>Classical approaches to data analysis made use of many subjects to
achieve statistical power. Traditionally, we measure a few things about
many people. For example cardiac disease risks can be based on a limited
number of factors in many patients (such as whether the patient smokes,
blood pressure, cholesterol levels etc). Because, traditionally, data
matrices are stored with individuals in rows and features in columns<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>, we refer to this as <em>depth</em>
of measurement. In statistics this is sometimes known as the <em>large
<span class="math inline">\(p\)</span>, small <span
class="math inline">\(n\)</span></em> domain because traditionally <span
class="math inline">\(p\)</span> is used to denote the number of
features we know about an individual and <span
class="math inline">\(n\)</span> is used to denote the number of
individuals.</p>
<p>The data-revolution is giving us access to far more detail about each
individual, this is leading to a <em>breadth</em> of coverage. This
characteristic first came to prominence in computational biology and
genomics where we became able to record information about mutations and
transcription in millions of genes. So <span
class="math inline">\(p\)</span> became very large, but due to expense
of measurement, the number of patients recorded, <span
class="math inline">\(n\)</span>, was relatively small. But we now see
this increasingly for other domains. With an increasing number of
sensors on our wrists or in our mobile phones, we are characterizing
indivdiuals in unprecedented detail. This domain can also be effectively
dealt with by modifying the models that are used for the data.</p>
<!-- https://upload.wikimedia.org/wikipedia/commons/5/5b/Grib_skov.jpg-->
<p>So we can know an individual extremely well, or we can know a
population well. The saying “Can’t see the wood for the trees”, means we
are distracted by the individual trees in a forest, and can’t see the
wider context. This seems appropriate for what may be going on here. We
are becoming distracted by the information on the individual and we
can’t see the wider context of the data.</p>
<p>We know that a rigorous, randomized, study would characterize that
forest well, but it seems we are unwilling to invest the money required
to do that and the proxies we are using are no longer effective, perhaps
because of shifting patterns of behaviour driven by the rapidly evolving
digital world.</p>
<p>Further, it’s likely that we are interested in <em>strata</em> within
our data set. Equivalent to the structure within the forest: a clearing,
a transition between types of tree, a shift in the nature of the
undergrowth.</p>
<h2 id="examples">Examples</h2>
<p>Examples exhibiting this phenomenon include recent elections, which
have proven difficult to predict. Including, the UK 2015 elections, the
EU referendum, the US 2016 elections and the UK 2017 elections. In each
case individuals may have taken actions on the back of polls that showed
one thing or another but turned out to be inaccurate. Indeed, the only
accurate pre-election poll for the UK 2017 election, <a
href="https://yougov.co.uk/news/2017/05/31/how-yougov-model-2017-general-election-works/">the
YouGov poll</a>, was not a traditional poll, it contains a new type of
statistical model called <a
href="http://andrewgelman.com/2013/10/09/mister-p-whats-its-secret-sauce/">Multilevel
Regression and Poststratification (MRP)</a> <span class="citation"
data-cites="Gelman:multilevel06">(Gelman and Hill, 2006)</span>.</p>
<p>Another example is stratified medicine. If a therapy is effective
only in a sub-type of a disease, then statistical power can be lost
across the whole population, particularly when that sub-type is a
minority. But characterization of that sub-type is difficult. For
example, new cancer immunotherapy treatments can have a dramatic effect,
leading to almost total elimination of the cancer in some patients, but
characterizing this sub-population is hard. This also makes it hard to
develop clinical trials that prove the efficacy of the drugs.</p>
<p>A final example is our measurement of our economy, which increasingly
may not capture where value is being generated. This is characterized by
the changing nature of work, and the way individuals contribute towards
society. For example, the open source community has driven the backbone
of the majority of operating system software we use today, as well as
cloud compute. But this value is difficult to measure as it was
contributed by volunteers, not by a traditional corporate structure.
Data itself may be driving this change, because the value of data
accumulates in a similar way to the value of capital. The movement of
data in the economy, and the value it generates is also hard to measure,
and it seems there may be a large class of “have nots”, in terms of
those industries whose productivity has suffered relative to the top
performers. The so-called productivity gap may not just be due to skills
and infrastructure, but also due to data-skills and
data-infrastructure.</p>
<h2 id="challenges-1">Challenges</h2>
<p>The nature of the digital society has a closed loop feedback on
itself. This is characterized by social media memes, which focus
attention on particular issues very quickly. A good example being the
photograph of Aylan Kurdi, the young Syrian boy found drowned on a
Turkish beach. This photograph had a dramatic effect on attitudes
towards immigration, more than the statistics that were showing that
thousands were dieing in the Mediterranean each month (see <a
href="https://www.dropbox.com/s/hnydewwtido6nhv/VISSOCMEDLAB_AYLAN%20KURDI%20REPORT.pdf?dl=0">this
report by the University of Sheffield’s Social Media Lab</a>).
Similarly, the changed dynamics of our social circles. Filter bubbles,
where our searches and/or newsfeed has been personalized to things that
algorithms already know we like. Echo chambers, where we interact mainly
with people we agree with and our opinions aren’t challenged. Each of
these is changing the dynamic of society, and yet there is a strong
temptation to use digital media for surveying information.</p>
<h2 id="solutions">Solutions</h2>
<p>The solutions to these challenges come in three flavours. Firstly,
there is a need for more data. In particular data that is actively
acquired to cover the gaps in our knowledge. We also need more use of
classical statistical techniques, and a wider understanding of what they
involve. This situation reminds me somewhat of the idea of the
‘paperless office’. The innovative research at Xerox PARC that brought
us the Graphical User Interface, so prevalent today, was driven by the
realization, in the 1970s that eventually offices would stop using
paper. Xerox focussed research on what that office would look like as it
was a perceived threat to their business. The paperless office may still
come, but in practice computers brought about a significant increase in
the need for paper due to the additional amounts of information that
they caused to be summarized or generated. In a similar way, the world
of <em>big data</em> is driving a need for more experimental design and
more classical statistics. Any perception of the automated computer
algorithm that drives all before it is at least as far away as the
paperless office was in the 1970s.</p>
<p>We also need a better social, cognitive and biological understanding
of humans and how we and our social structures respond to these
interventions. Over time some of the measurables will likely stabilize,
but it is not yet clear which ones.</p>
<h2 id="big-model-paradox">Big Model Paradox</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/big-model-paradox.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/big-model-paradox.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The big data paradox has a sister: the big model paradox. As we build
more and more complex models, we start believing that we have a
high-fidelity representation of reality. But the complexity of reality
is way beyond our feeble imaginings. So we end up with a highly complex
model, but one that falls well short in terms of reflecting reality. The
complexity of the model means that it moves beyond our
understanding.</p>
<h2 id="increasing-need-for-human-judgment">Increasing Need for Human
Judgment</h2>
<div class="figure">
<div id="-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/ori6J8oR0jI?start=1350" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="-magnify" class="magnify" onclick="magnifyFigure(&#39;&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="-caption" class="caption-frame">
<p>Figure: Diane Coyle’s Fitzwilliam Lecture where she emphasises as
data increases, human judgment is <em>more</em> needed.</p>
</div>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip1">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Diane Coyle
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/advds/./slides/diagrams//people/diane-coyle.png" clip-path="url(#clip1)"/>
</svg>
</div>
<blockquote>
<p>The domain of human judgment is increasing.</p>
<p>How these firms use knowledge. How do they generate ideas?</p>
</blockquote>
<h2 id="data-as-a-convener">Data as a Convener</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_policy/includes/data-as-a-convener.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_policy/includes/data-as-a-convener.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>To improve communication, we need to ‘externalise cognition’: have
objects that are outside our brains, are persistent in the real world,
that we can combine with our individual knowledge. Doing otherwise
leaves us imagining the world as our personal domain-utopias, ignoring
the ugly realities of the way things actual progress.</p>
<p>Data can provide an excellent convener, because even if it doesn’t
exist it allows conversations to occur about what data should or could
exist and how it might allow us to address the questions of
importance.</p>
<p>Models, while also of great potential value in externalising
cognition, can be two complex to have conversations about and they can
entrench beliefs, triggering <em>model induced blindness</em> (a
variation on Kahneman’s <em>theory induced blindness</em> <span
class="citation" data-cites="Kahneman-fastslow11">(Kahneman,
2011)</span>).</p>
<div class="figure">
<div id="anne-bob-model-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/advds/./slides/diagrams//policy/anne-bob-model.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-model-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-bob-model&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-bob-model-caption" class="caption-frame">
<p>Figure: Models can also be used to externalise cognition, but if the
model is highly complex it’s difficult for two individuals to understand
each others’ models. This shuts down conversation, often “mathematical
intimidation” is used to shut down a line of questioning. This is highly
destructive of the necessary cognitive diversity.</p>
</div>
</div>
<p>Bandwidth constraints on individuals mean that they tend to focus on
their own specialism. This can be particularly problematic for those on
the more theoretical side, because mathematical models are complex, and
require a lot of deep thought. However, when communicating with others,
unless they have the same in depth experience of mathematical modelling
as the theoreticians, the models do not bring about good information
coherence. Indeed, many computational models themselves are so complex
now that no individual can understand the model whole.</p>
<div class="figure">
<div id="anne-bob-data-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/advds/./slides/diagrams//policy/anne-bob-data.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-data-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-bob-data&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-bob-data-caption" class="caption-frame">
<p>Figure: Data can be queried, but the simplest query, what data do we
need? Doesn’t even require the data to exist. It seems data can be
highly effective for convening a multidisciplinary conversation.</p>
</div>
</div>
<p>Fritz Heider referred to happenings that are “<em>psychologically
represented</em> in each of the participants” <span class="citation"
data-cites="Heider:interpersonal58">(Heider, 1958)</span> as a
prerequisite for conversation. Data is a route to that psychological
representation.</p>
<p><em>Note</em>: my introduction to Fritz Heider was through a talk by
Nick Chater in 2010, you can read Nick’s thoughts on these issues in his
book, <em>The Mind is Flat</em> <span class="citation"
data-cites="Chater:mindisflat19">(Chater, 2019)</span>.</p>
<h1 id="quantifying-the-value-of-data">Quantifying the Value of
Data</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/value-of-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/value-of-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The situation is reminiscent of a thirsty castaway, set adrift. There
is a sea of data, but it is not fit to drink. We need some form of data
desalination before it can be consumed. But like real desalination, this
is a non-trivial process, particularly if we want to achieve it at
scale.</p>
<p>There’s a sea of data, but most of it is undrinkable.</p>
<div class="figure">
<div id="sea-water-ocean-waves-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//sea-water-ocean-waves.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="sea-water-ocean-waves-magnify" class="magnify"
onclick="magnifyFigure(&#39;sea-water-ocean-waves&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="sea-water-ocean-waves-caption" class="caption-frame">
<p>Figure: The abundance of uncurated data is reminiscent of the
abundance of undrinkable water for those cast adrift at sea.</p>
</div>
</div>
<p>We require data-desalination before it can be consumed!</p>
<p>I spoke about the challenges in data science at the NIPS 2016
Workshop on Machine Learning for Health. NIPS mainly focuses on machine
learning methodologies, and many of the speakers were doing so. But
before my talk, I listened to some of the other speakers talk about the
challenges they had with data preparation.</p>
<ul>
<li>90% of our time is spent on validation and integration (Leo Anthony
Celi)</li>
<li>“The Dirty Work We Don’t Want to Think About” (Eric Xing)</li>
<li>“Voodoo to get it decompressed” (Francisco Giminez)</li>
</ul>
<p>A further challenge in healthcare is that the data is collected by
clinicians, often at great inconvenience to both themselves and the
patient, but the control of the data is sometimes used to steer the
direction of research.</p>
<p>The fact that we put so much effort into processing the data, but so
little into allocating credit for this work is a major challenge for
realizing the benefit in the data we have.</p>
<p>This type of work is somewhat thankless, with the exception of the
clinicians’ control of the data, which probably takes things too far,
those that collate and correct data sets gain little credit. In the
domain of <em>reinforcement learning</em> the aim is to take a series of
actions to achieve a stated goal and gain a reward. The <em>credit
assignment problem</em> is the challenge in the learning algorithm of
distributing credit to each of the actions which brought about the
reward. We also experience this problem in society, we use proxies such
as monetary reward to incentivise intermediate steps in our economy.
Modern society functions because we agree to make basic expenditure on
infrastructure, such as roads, which we all make use of. Our
data-society is not sufficiently mature to be correctly crediting and
rewarding those that undertake this work.</p>
<p>This situation is no better in industry than in academia. Many
companies have been persuaded to accumulate all their data centrally in
a so-called “data lake”. This attractive idea is problematic, because
data is added to the “lake” without thought to its quality. As a result,
a better name for these resources would be data swamps. Because the
quality of data in them is often dubious. Data scientists when working
with these sources often need to develop their own processes for
checking the quality of the data before it is used. Unfortunately, the
quality improvements they make are rarely fed back into the ecosystem,
meaning the same purification work needs to be done repeatedly.</p>
<p>We need to properly incentivize the sharing and production of clean
data sets, we need to correctly quantify the value in the contribution
of each actor, otherwise there won’t be enough clean data to satiate the
thirst of our decision-making processes.</p>
<div class="figure">
<div id="pomdp-credit-assignment-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/advds/./slides/diagrams//pomdp004.svg" width="80%" style=" ">
</object>
</div>
<div id="pomdp-credit-assignment-magnify" class="magnify"
onclick="magnifyFigure(&#39;pomdp-credit-assignment&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="pomdp-credit-assignment-caption" class="caption-frame">
<p>Figure: Partially observable Markov decision process observing reward
as actions are taken in different states</p>
</div>
</div>
<p>The value of shared data infrastructures in computational biology was
recognized by the 2010 joint statement from the Wellcome Trust and other
funders of research at the “Foggy Bottom” meeting. They recognised three
key benefits to sharing of health data:</p>
<ul>
<li>faster progress in improving health</li>
<li>better value for money</li>
<li>higher quality science</li>
</ul>
<p>But incentivising sharing requires incentivising collection and
collation of data, and the associated credit allocation models.</p>
<h2 id="data-readiness-levels">Data Readiness Levels</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-readiness-levels.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-readiness-levels.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h3 id="data-readiness-levels-1">Data Readiness Levels</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-readiness-levels-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-readiness-levels-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><a
href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data
Readiness Levels</a> <span class="citation"
data-cites="Lawrence-drl17">(Lawrence, 2017)</span> are an attempt to
develop a language around data quality that can bridge the gap between
technical solutions and decision makers such as managers and project
planners. They are inspired by Technology Readiness Levels which attempt
to quantify the readiness of technologies for deployment.</p>
<p>See this blog post on <a
href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data
Readiness Levels</a>.</p>
<h3 id="three-grades-of-data-readiness">Three Grades of Data
Readiness</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/three-grades-of-data-readiness.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/three-grades-of-data-readiness.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Data-readiness describes, at its coarsest level, three separate
stages of data graduation.</p>
<ul>
<li>Grade C - accessibility
<ul>
<li>Transition: data becomes electronically available</li>
</ul></li>
<li>Grade B - validity
<ul>
<li>Transition: pose a question to the data.</li>
</ul></li>
<li>Grade A - usability</li>
</ul>
<p>The important definitions are at the transition. The move from Grade
C data to Grade B data is delimited by the <em>electronic
availability</em> of the data. The move from Grade B to Grade A data is
delimited by posing a question or task to the data <span
class="citation" data-cites="Lawrence-drl17">(Lawrence,
2017)</span>.</p>
<h2 id="accessibility-grade-c">Accessibility: Grade C</h2>
<p>The first grade refers to the accessibility of data. Most data
science practitioners will be used to working with data-providers who,
perhaps having had little experience of data-science before, state that
they “have the data”. More often than not, they have not verified this.
A convenient term for this is “Hearsay Data”, someone has <em>heard</em>
that they have the data so they <em>say</em> they have it. This is the
lowest grade of data readiness.</p>
<p>Progressing through Grade C involves ensuring that this data is
accessible. Not just in terms of digital accessiblity, but also for
regulatory, ethical and intellectual property reasons.</p>
<h2 id="validity-grade-b">Validity: Grade B</h2>
<p>Data transits from Grade C to Grade B once we can begin digital
analysis on the computer. Once the challenges of access to the data have
been resolved, we can make the data available either via API, or for
direct loading into analysis software (such as Python, R, Matlab,
Mathematica or SPSS). Once this has occured the data is at B4 level.
Grade B involves the <em>validity</em> of the data. Does the data really
represent what it purports to? There are challenges such as missing
values, outliers, record duplication. Each of these needs to be
investigated.</p>
<p>Grade B and C are important as if the work done in these grades is
documented well, it can be reused in other projects. Reuse of this
labour is key to reducing the costs of data-driven automated decision
making. There is a strong overlap between the work required in this
grade and the statistical field of <a
href="https://en.wikipedia.org/wiki/Exploratory_data_analysis"><em>exploratory
data analysis</em></a> <span class="citation"
data-cites="Tukey:exploratory77">(Tukey, 1977)</span>.</p>
<p>The need for Grade B emerges due to the fundamental change in the
availability of data. Classically, the scientific question came first,
and the data came later. This is still the approach in a randomized
control trial, e.g. in A/B testing or clinical trials for drugs. Today
data is being laid down by happenstance, and the question we wish to ask
about the data often comes after the data has been created. The Grade B
of data readiness ensures thought can be put into data quality
<em>before</em> the question is defined. It is this work that is
reusable across multiple teams. It is these processes that the team
which is <em>standing up</em> the data must deliver.</p>
<h2 id="usability-grade-a">Usability: Grade A</h2>
<p>Once the validity of the data is determined, the data set can be
considered for use in a particular task. This stage of data readiness is
more akin to what machine learning scientists are used to doing in
universities. Bringing an algorithm to bear on a well understood data
set.</p>
<p>In Grade A we are concerned about the utility of the data given a
particular task. Grade A may involve additional data collection
(experimental design in statistics) to ensure that the task is
fulfilled.</p>
<p>This is the stage where the data and the model are brought together,
so expertise in learning algorithms and their application is key.
Further ethical considerations, such as the fairness of the resulting
predictions are required at this stage. At the end of this stage a
prototype model is ready for deployment.</p>
<p>Deployment and maintenance of machine learning models in production
is another important issue which Data Readiness Levels are only a part
of the solution for.</p>
<h2 id="recursive-effects">Recursive Effects</h2>
<p>To find out more, or to contribute ideas go to <a
href="http://data-readiness.org"
class="uri">http://data-readiness.org</a></p>
<p>Throughout the data preparation pipeline, it is important to have
close interaction between data scientists and application domain
experts. Decisions on data preparation taken outside the context of
application have dangerous downstream consequences. This provides an
additional burden on the data scientist as they are required for each
project, but it should also be seen as a learning and familiarization
exercise for the domain expert. Long term, just as biologists have found
it necessary to assimilate the skills of the bioinformatician to be
effective in their science, most domains will also require a familiarity
with the nature of data driven decision making and its application.
Working closely with data-scientists on data preparation is one way to
begin this sharing of best practice.</p>
<p>The processes involved in Grade C and B are often badly taught in
courses on data science. Perhaps not due to a lack of interest in the
areas, but maybe more due to a lack of access to real world examples
where data quality is poor.</p>
<p>These stages of data science are also ridden with ambiguity. In the
long term they could do with more formalization, and automation, but
best practice needs to be understood by a wider community before that
can happen.</p>
<h1 id="assessing-the-organizations-readiness">Assessing the
Organizations Readiness</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-joel-tests.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-joel-tests.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Assessing the readiness of data for analysis is one action that can
be taken, but assessing teams that need to assimilate the information in
the data is the other side of the coin. With this in mind both <a
href="https://medium.com/@damoncivin/the-joel-test-for-data-readiness-4882aae64753">Damon
Civin</a> and <a
href="https://blog.dominodatalab.com/joel-test-data-science/">Nick
Elprin</a> have independently proposed the idea of a “Data Joel Test”. A
“<a
href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/">Joel
Test</a>” is a short questionnaire to establish the ability of a team to
handle software engineering tasks. It is designed as a rough and ready
capability assessment. A “Data Joel Test” is similar, but for assessing
the capability of a team in performing data science.</p>
<h2 id="privacy-loss-of-control-and-marginalization">Privacy, Loss of
Control and Marginalization</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/privacy-intro.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/privacy-intro.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Society is becoming harder to monitor, but the individual is becoming
easier to monitor. Social media monitoring for ‘hate speech’ can easily
be turned to monitoring of political dissent. Marketing becomes more
sinister when the target of the marketing is so well understood and the
digital environment of the target is so well controlled.</p>
<h2 id="marketing-and-free-will">Marketing and Free Will</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/marketing-and-free-will.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/marketing-and-free-will.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>What does it mean for our free will if a computer can predict our
individual behavior better than we ourselves can?</p>
<p>There is potential for both explicit and implicit discrimination on
the basis of race, religion, sexuality or health status. All of these
are prohibited under European law but can pass unawares or be
implicit.</p>
<p>The GDPR is the General Data Protection Regulation, but a better name
for it would simply be Good Data Practice Rules. It covers how to deal
with discrimination which has a consequential effect on the individual.
For example, entrance to university, access to loans or insurance. But
the new phenomenon is dealing with a series of inconsequential decisions
that taken together have a consequential effect.</p>
<div class="figure">
<div id="woman-tends-house-in-village-of-uganda-africa-figure"
class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//woman-tends-house-in-village-of-uganda-africa.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="woman-tends-house-in-village-of-uganda-africa-magnify"
class="magnify"
onclick="magnifyFigure(&#39;woman-tends-house-in-village-of-uganda-africa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="woman-tends-house-in-village-of-uganda-africa-caption"
class="caption-frame">
<p>Figure: A woman tends her house in a village in Uganda.</p>
</div>
</div>
<p>Statistics as a community is also focused on the single consequential
effect of an analysis (efficacy of drugs, or distribution of Mosquito
nets). Associated with happenstance data is <em>happenstance decision
making</em>.</p>
<p>These algorithms behind these decisions are developed in a particular
context. The so-called Silicon Valley bubble. But they are deployed
across the world. To address this, a key challenge is capacity building
in contexts which are remote from the Western norm.</p>
<h2 id="amelioration">Amelioration</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/privacy-amelioration.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/privacy-amelioration.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Addressing challenges in privacy, loss of control and marginalization
includes ensuring that the individual retains control of their own data.
We accept privacy in our real loves, we need to accept it in our digital
persona. This is vital for our control of persona and our ability to
project ourselves.</p>
<p>Fairness goes hand in hand with privacy to protect the individual.
Regulations like the GDPR date from a time where the main worry was
<em>consequential</em> decision making. Today we also face problems from
accumulation of inconsequential decisions leading to a resulting
consequential effect.</p>
<p>Capacity building in different contexts, empowering domain experts to
solve their own problems, is one aspect to the solution. A further
proposal is the use of data trusts to reintroduce control of personal
data for the individual.</p>
<h1 id="delve">Delve</h1>
<h2 id="delve-reports">Delve Reports</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_delve/includes/delve-report-list.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_delve/includes/delve-report-list.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ol type="1">
<li>Facemasks <em>4th May 2020</em> <span class="citation"
data-cites="Delve-facemasks20">(The DELVE Initiative, 2020a)</span></li>
<li>Test, Trace, Isolate <em>27th May 2020</em> <span class="citation"
data-cites="Delve-tti20">(The DELVE Initiative, 2020b)</span></li>
<li>Nosocomial Infections <em>6th July 2020</em> <span class="citation"
data-cites="Delve-hospital20">(The DELVE Initiative, 2020c)</span></li>
<li>Schools <em>24th July 2020</em> <span class="citation"
data-cites="Delve-schools20">(The DELVE Initiative, 2020d)</span></li>
<li>Economics <em>14th August 2020</em> <span class="citation"
data-cites="Delve-economics20">(The DELVE Initiative, 2020e)</span></li>
<li>Vaccines <em>1st October 2020</em> <span class="citation"
data-cites="Delve-vaccine20">(The DELVE Initiative, 2020f)</span></li>
<li>Data <em>24th November 2020</em> <span class="citation"
data-cites="Delve-data20">(The DELVE Initiative, 2020g)</span></li>
</ol>
<p>There is lots of hope for the role data science and AI could play,
but we’re still a way off from being AI-ready. Further attention is
needed on some of the foundational issues around data use – access,
skills, culture – before we can begin to talk in earnest about deploying
AI. [link here to data readiness]</p>
<h2 id="delve-data-report">Delve Data Report</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_delve/includes/delve-data-report.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_delve/includes/delve-data-report.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The DELVE Initiative was established with the ambition that data
science could play a role in helping develop policy responses to the
COVID-19 pandemic, by identifying lessons from the responses of other
countries or by combining datasets to generate novel insights. Such
analysis requires access to data, which could come from both official
statistics, or from so-called happenstance data, generated as a
by-product of daily activities. Drawing from a multidisciplinary team of
domain experts in policy, public health, economics, education,
immunology, epidemiology, and social science, alongside statisticians,
mathematicians, computer scientists and machine learning scientists,
DELVE set out to provide advice and analysis that could feed into live
policy decisions.</p>
<p>Our report focusses on what more we can do to ensure that this data
is readily available <span class="citation"
data-cites="Delve-data20">(The DELVE Initiative, 2020g)</span>.</p>
<h2 id="delve-data-report-recommendations">Delve Data Report:
Recommendations</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_delve/includes/data-report-recommendations.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_delve/includes/data-report-recommendations.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li><p>Government should update the statutory objective of the Office
for National Statistics (ONS) to accommodate trustworthy access to
happenstance data to generate national and local statistics. Such
statistics are required on very short time frames to facilitate fast
decision-making for the nation in the rapidly evolving circumstances of
a national emergency.</p></li>
<li><p>The ONS should collaborate closely with the Information
Commissioner’s Office (ICO) to formulate a standardized qualification
for data access, equivalent to a ‘data driving license’ that would
demonstrate trustworthiness and ensure that qualified experts can get
rapid access to different data types with the appropriate standardized
ethical and legal training in place.</p></li>
<li><p>Government should fund interdisciplinary pathfinder data
projects. These projects should require collaborations between
industries, run across government departments and integrate different
academic expertise. Each project should target a specific policy
question. Beyond the pathfinder role, the projects will leave a legacy
in the form of expertise and guidance in understanding the stages of the
data-sharing pipeline. Priority areas for pathfinder projects
include:</p>
<ul>
<li><p>Nowcasting of economic metrics: At least one of these pathfinder
projects should create a close collaboration between Cabinet Office and
Treasury around nowcasting of classical economic metrics (such as GDP)
from happenstance data (e.g. payments data). Efficient resourcing and
strategic implementation of data sharing projects will only be possible
if Treasury and Cabinet Office are aligned on plausible benefits and
costs of data sharing projects.</p></li>
<li><p>Mobility data: Another project should drive a step-change in the
use of mobility data for public policy. To achieve this, the ONS should
act as the trusted body to convert happenstance data into high-frequency
population mobility statistics. One pathfinder project should produce
daily views of population mobility between geographic regions,
aggregated from origin to destination counts from mobile phone
operators.</p></li>
</ul></li>
</ul>
<p>Delivering a rapid response requires the ability to quickly convene
teams from across disciplines (and often institutions) around a key
question. To facilitate this, we also used ideas from blog post on <a
href="http://inverseprobability.com/2014/07/01/open-data-science">open
data science</a>. to facilitate communication and understanding.</p>
<h2 id="personal-data-trusts">Personal Data Trusts</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_governance/includes/data-trusts.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_governance/includes/data-trusts.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The machine learning solutions we are dependent on to drive automated
decision making are dependent on data. But with regard to personal data
there are important issues of privacy. Data sharing brings benefits, but
also exposes our digital selves. From the use of social media data for
targeted advertising to influence us, to the use of genetic data to
identify criminals, or natural family members. Control of our virtual
selves maps on to control of our actual selves.</p>
<p>The feudal system that is implied by current data protection
legislation has significant power asymmetries at its heart, in that the
data controller has a duty of care over the data subject, but the data
subject may only discover failings in that duty of care when it’s too
late. Data controllers also may have conflicting motivations, and often
their primary motivation is <em>not</em> towards the data-subject, but
that is a consideration in their wider agenda.</p>
<p><a
href="https://www.theguardian.com/media-network/2016/jun/03/data-trusts-privacy-fears-feudalism-democracy">Personal
Data Trusts</a> <span class="citation"
data-cites="Edwards:privacy04 Lawrence:trusts16 Delacroix:trusts18">(Delacroix
and Lawrence, 2018; Edwards, 2004; Lawrence, 2016)</span> are a
potential solution to this problem. Inspired by <em>land societies</em>
that formed in the 19th century to bring democratic representation to
the growing middle classes. A land society was a mutual organization
where resources were pooled for the common good.</p>
<p>A Personal Data Trust would be a legal entity where the trustees’
responsibility was entirely to the members of the trust. So the
motivation of the data-controllers is aligned only with the
data-subjects. How data is handled would be subject to the terms under
which the trust was convened. The success of an individual trust would
be contingent on it satisfying its members with appropriate balancing of
individual privacy with the benefits of data sharing.</p>
<p>Formation of Data Trusts became the number one recommendation of the
Hall-Presenti report on AI, but unfortunately, the term was confounded
with more general approaches to data sharing that don’t necessarily
involve fiduciary responsibilities or personal data rights. It seems
clear that we need to better characterize the data sharing landscape as
well as propose mechanisms for tackling specific issues in data
sharing.</p>
<p>It feels important to have a diversity of approaches, and yet it
feels important that any individual trust would be large enough to be
taken seriously in representing the views of its members in wider
negotiations.</p>
<div class="figure">
<div id="data-trusts-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//data-science/data-trusts.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="data-trusts-magnify" class="magnify"
onclick="magnifyFigure(&#39;data-trusts&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="data-trusts-caption" class="caption-frame">
<p>Figure: For thoughts on data trusts see Guardian article on <a
href="https://www.theguardian.com/media-network/https://www.theguardian.com/media-network/2016/jun/03/data-trusts-privacy-fears-feudalism-democracy">Data
Trusts</a>.</p>
</div>
</div>
<div class="figure">
<div id="hall-presenti-report-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//data-science/data-trusts-review.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="hall-presenti-report-magnify" class="magnify"
onclick="magnifyFigure(&#39;hall-presenti-report&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="hall-presenti-report-caption" class="caption-frame">
<p>Figure: Data Trusts were the first recommendation of the
<a href="https://www.out-law.com/en/articles/2017/october/review-calls-for-data-trusts-to-help-grow-artificial-intelligence-in-the-uk/" target="_blank">Hall-Presenti
Report</a>. More recently the nature of different data intermediaries
was clarified in a report on
<a href="legal mechanisms for data sharing" target="_blank">https://www.adalovelaceinstitute.org/report/legal-mechanisms-data-stewardship/</a>
from the Ada Lovelace Institute.</p>
</div>
</div>
<p>See Guardian article on <a
href="https://www.theguardian.com/media-network/https://www.theguardian.com/media-network/2015/mar/05/digital-oligarchy-algorithms-personal-data">Digital
Oligarchies</a> and Guardian article on <a
href="https://www.theguardian.com/media-network/https://www.theguardian.com/media-network/2015/nov/16/information-barons-threaten-autonomy-privacy-online">Information
Feudalism</a>.</p>
<h2 id="data-trusts-initiative">Data Trusts Initiative</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_governance/includes/data-trusts-initiative.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_governance/includes/data-trusts-initiative.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The <a href="https://datatrusts.uk/">Data Trusts Initiative</a>,
funded by the Patrick J. McGovern Foundation is supporting three pilot
projects that consider how bottom-up empowerment can redress the
imbalance associated with the digital oligarchy.</p>
<div class="figure">
<div id="data-trusts-initiative-website-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//governance/data-trusts-initiative-project-page.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="data-trusts-initiative-website-magnify" class="magnify"
onclick="magnifyFigure(&#39;data-trusts-initiative-website&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="data-trusts-initiative-website-caption" class="caption-frame">
<p>Figure: The Data Trusts Initiative
(<a href="https://datatrusts.uk/" target="_blank">http://datatrusts.uk</a>)
hosts blog posts helping build understanding of data trusts and supports
research and pilot projects.</p>
</div>
</div>
<h2 id="progress-so-far">Progress So Far</h2>
<p>In its first 18 months of operation, the Initiative has:</p>
<ul>
<li><p>Convened over 200 leading data ethics researchers and
practitioners;</p></li>
<li><p>Funded 7 new research projects tackling knowledge gaps in data
trust theory and practice;</p></li>
<li><p>Supported 3 real-world data trust pilot projects establishing new
data stewardship mechanisms.</p></li>
</ul>
<h2 id="data-science-africa">Data Science Africa</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-science-africa.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/data-science-africa.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="data-science-africa-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//data-science-africa-logo.png" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="data-science-africa-magnify" class="magnify"
onclick="magnifyFigure(&#39;data-science-africa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="data-science-africa-caption" class="caption-frame">
<p>Figure: Data Science Africa <a href="http://datascienceafrica.org"
class="uri">http://datascienceafrica.org</a> is a ground up initiative
for capacity building around data science, machine learning and
artificial intelligence on the African continent.</p>
</div>
</div>
<div class="figure">
<div id="dsa-events-october-2021-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/advds/./slides/diagrams//dsa/dsa-events-october-2021.svg" width="60%" style=" ">
</object>
</div>
<div id="dsa-events-october-2021-magnify" class="magnify"
onclick="magnifyFigure(&#39;dsa-events-october-2021&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="dsa-events-october-2021-caption" class="caption-frame">
<p>Figure: Data Science Africa meetings held up to October 2021.</p>
</div>
</div>
<p>Data Science Africa is a bottom up initiative for capacity building
in data science, machine learning and artificial intelligence on the
African continent.</p>
<p>As of May 2023 there have been eleven workshops and schools, located
in seven different countries: Nyeri, Kenya (twice); Kampala, Uganda;
Arusha, Tanzania; Abuja, Nigeria; Addis Ababa, Ethiopia; Accra, Ghana;
Kampala, Uganda and Kimberley, South Africa (virtual), and in Kigali,
Rwanda.</p>
<p>The main notion is <em>end-to-end</em> data science. For example,
going from data collection in the farmer’s field to decision making in
the Ministry of Agriculture. Or going from malaria disease counts in
health centers to medicine distribution.</p>
<p>The philosophy is laid out in <span class="citation"
data-cites="Lawrence:dsa15">(Lawrence, 2015)</span>. The key idea is
that the modern <em>information infrastructure</em> presents new
solutions to old problems. Modes of development change because less
capital investment is required to take advantage of this infrastructure.
The philosophy is that local capacity building is the right way to
leverage these challenges in addressing data science problems in the
African context.</p>
<p>Data Science Africa is now a non-govermental organization registered
in Kenya. The organising board of the meeting is entirely made up of
scientists and academics based on the African continent.</p>
<div class="figure">
<div id="africa-benefit-data-revolution-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/advds/./slides/diagrams//data-science/africa-benefit-data-revolution.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="africa-benefit-data-revolution-magnify" class="magnify"
onclick="magnifyFigure(&#39;africa-benefit-data-revolution&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="africa-benefit-data-revolution-caption" class="caption-frame">
<p>Figure: The lack of existing physical infrastructure on the African
continent makes it a particularly interesting environment for deploying
solutions based on the <em>information infrastructure</em>. The idea is
explored more in this Guardian op-ed on Guardian article on <a
href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information">How
African can benefit from the data revolution</a>.</p>
</div>
</div>
<p>Guardian article on <a
href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information">Data
Science Africa</a></p>
<p>We separated the challenges we face into three groups: (1) paradoxes
of the odern data society, (2) quantifying the value of data and (3)
privacy loss of control and marginalization. We’ve noted the origins of
the paradoxes, speculating that it is based in a form of data (or
modelling) inattention bias demonstrated through the Gorilla. We’ve
drawn parallels between challenges of rewarding the addition of value
and the credit assignment problem in reinforecement learning and we’ve
looked at approaches to introduce the voice of marginalized societies
and people into the conversation.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The particular circumstances of the Covid-19 pandemic have
highlighted the challenges of integrating scientific ideas to answer
policy questions. In this talk, we’ve given a formal introduction to the
problem, the difficulty of communicating between individuals
(particularly from different domains) and reviewed the ideas and
solutions we used in the Delve initiative.</p>
<p>Recommendations from the DELVE Data report suggest that more effort
needs to be placed into working in this manner in normal circumstances,
so that when an emergency occurs we are better prepared to deal with the
questions we face. Other approaches prosed include data trusts.</p>
<p>When we combine these difficult challenges with complex models, we
need to put more effort into decomposing our models so that they may be
calibrated and re-integrated at appropriate fidelities.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to
check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking
Machines</a></li>
<li>newspaper: <a
href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile
Page</a></li>
<li>blog: <a
href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Chater:mindisflat19" class="csl-entry" role="listitem">
Chater, N., 2019. The mind is flat. Penguin.
</div>
<div id="ref-Delacroix:trusts18" class="csl-entry" role="listitem">
Delacroix, S., Lawrence, N.D., 2018. Disturbing the <span>“one size fits
all”</span> approach to data governance: Bottom-up data trusts. SSRN. <a
href="https://doi.org/10.1093/idpl/ipz01410.2139/ssrn.3265315">https://doi.org/10.1093/idpl/ipz01410.2139/ssrn.3265315</a>
</div>
<div id="ref-Edwards:privacy04" class="csl-entry" role="listitem">
Edwards, L., 2004. The problem with privacy. International Review of Law
Computers &amp; Technology 18, 263–294.
</div>
<div id="ref-Felin-data20" class="csl-entry" role="listitem">
Felin, T., Koenderink, J., Krueger, J.I., Noble, D., Ellis, G.F.R.,
2021. The data-hypothesis relationship. Genome Biology 22. <a
href="https://doi.org/10.1186/s13059-021-02276-4">https://doi.org/10.1186/s13059-021-02276-4</a>
</div>
<div id="ref-Gelman:multilevel06" class="csl-entry" role="listitem">
Gelman, A., Hill, J., 2006. Data analysis using regression and
multilevel/hierarchical models, Analytical methods for social research.
Cambridge University Press, Cambridge, UK. <a
href="https://doi.org/10.1017/CBO9780511790942">https://doi.org/10.1017/CBO9780511790942</a>
</div>
<div id="ref-Heider:interpersonal58" class="csl-entry" role="listitem">
Heider, F., 1958. The psychology of interpersonal relations. John Wiley.
</div>
<div id="ref-Kahneman-fastslow11" class="csl-entry" role="listitem">
Kahneman, D., 2011. Thinking fast and slow.
</div>
<div id="ref-Lawrence-drl17" class="csl-entry" role="listitem">
Lawrence, N.D., 2017. Data readiness levels. ArXiv.
</div>
<div id="ref-Lawrence:trusts16" class="csl-entry" role="listitem">
Lawrence, N.D., 2016. <a
href="https://www.theguardian.com/media-network/2016/jun/03/data-trusts-privacy-fears-feudalism-democracy">Data
trusts could allay our privacy fears</a>.
</div>
<div id="ref-Lawrence:dsa15" class="csl-entry" role="listitem">
Lawrence, N.D., 2015. <a
href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information">How
<span>A</span>frica can benefit from the data revolution</a>.
</div>
<div id="ref-Lawrence:licsbintro10" class="csl-entry" role="listitem">
Lawrence, N.D., 2010. Introduction to learning and inference in
computational systems biology.
</div>
<div id="ref-Simons-gorillas99" class="csl-entry" role="listitem">
Simons, D.J., Chabris, C.F., 1999. Gorillas in our midst: Sustained
inattentional blindness for dynamic events. Perception 28, 1059–1074. <a
href="https://doi.org/10.1068/p281059">https://doi.org/10.1068/p281059</a>
</div>
<div id="ref-Spiegelhalter-art19" class="csl-entry" role="listitem">
Spiegelhalter, D.J., 2019. The art of statistics. Pelican.
</div>
<div id="ref-Delve-data20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020g. <a
href="http://rs-delve.github.io/reports/2020/11/24/data-readiness-lessons-from-an-emergency.html">Data
readiness: Lessons from an emergency</a>. The Royal Society.
</div>
<div id="ref-Delve-economics20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020e. <a
href="https://rs-delve.github.io/reports/2020/08/14/economic-aspects-of-the-covid19-crisis-in-the-uk.html">Economic
aspects of the COVID-19 crisis in the UK</a>. The Royal Society.
</div>
<div id="ref-Delve-facemasks20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020a. <a
href="https://rs-delve.github.io/reports/2020/05/04/face-masks-for-the-general-public.html">Face
masks for the general public</a>. The Royal Society.
</div>
<div id="ref-Delve-hospital20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020c. <a
href="https://rs-delve.github.io/reports/2020/07/06/nosocomial-scoping-report.html">Scoping
report on hospital and health care acquisition of COVID-19 and its
control</a>. The Royal Society.
</div>
<div id="ref-Delve-schools20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020d. <a
href="https://rs-delve.github.io/reports/2020/07/24/balancing-the-risk-of-pupils-returning-to-schools.html">Balancing
the risks of pupils returning to schools</a>. The Royal Society.
</div>
<div id="ref-Delve-tti20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020b. <a
href="https://rs-delve.github.io/reports/2020/05/27/test-trace-isolate.html">Test,
trace, isolate</a>. The Royal Society.
</div>
<div id="ref-Delve-vaccine20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020f. <a
href="http://rs-delve.github.io/reports/2020/10/01/covid19-vaccination-report.html">SARS-CoV-2
vaccine development &amp; implementation; scenarios, options, key
decisions</a>. The Royal Society.
</div>
<div id="ref-Tukey:exploratory77" class="csl-entry" role="listitem">
Tukey, J.W., 1977. Exploratory data analysis. Addison-Wesley.
</div>
<div id="ref-Yanai-hypothesis20" class="csl-entry" role="listitem">
Yanai, I., Lercher, M., 2020. A hypothesis is a liability. Genome
Biology 21.
</div>
</div>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>In statistics this is known as a <em>design matrix</em>,
representing the design of a study. But in databases, one might think of
each patient being in a row, or record of the database.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

